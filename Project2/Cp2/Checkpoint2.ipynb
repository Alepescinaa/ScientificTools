{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Alepescinaa/ScientificTools/blob/main/Project2/Cp2/Checkpoint2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "essential-american",
      "metadata": {
        "id": "essential-american"
      },
      "source": [
        "# Optimal well disposition for the Darcy problem"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!git clone https://github.com/Alepescinaa/ScientificTools\n",
        "%cd ScientificTools/Project2/Cp2\n",
        "\n",
        "!apt-get update\n",
        "!apt-get install libglu1-mesa\n",
        "\n",
        "!git clone https://github.com/pmgbergen/porepy.git\n",
        "%cd porepy\n",
        "\n",
        "!git checkout main\n",
        "\n",
        "!pip install -r requirements.txt\n",
        "\n",
        "!pip install .\n",
        "\n",
        "%cd .."
      ],
      "metadata": {
        "id": "KN9kDR_WshqK"
      },
      "id": "KN9kDR_WshqK",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "planned-danger",
      "metadata": {
        "id": "planned-danger"
      },
      "source": [
        "First we import some of the standard modules."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "dietary-perth",
      "metadata": {
        "id": "dietary-perth",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "262dd886-44a4-44f6-90c5-a111f857c4e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/porepy/numerics/nonlinear/nonlinear_solvers.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
            "  from tqdm.autonotebook import trange  # type: ignore\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import scipy\n",
        "import numpy as np\n",
        "import porepy as pp\n",
        "import multiprocessing\n",
        "import scipy.sparse as sps"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fd7d2c82",
      "metadata": {
        "id": "fd7d2c82"
      },
      "source": [
        "Depending on the setting, we then need to setup the local path for importing some useful functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "bdef9bd1",
      "metadata": {
        "id": "bdef9bd1"
      },
      "outputs": [],
      "source": [
        "main_folder = \"./\"\n",
        "spe10_folder = main_folder + \"spe10\"\n",
        "sys.path.insert(1, spe10_folder)\n",
        "\n",
        "from functions import *\n",
        "from spe10 import Spe10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "0d4ff136",
      "metadata": {
        "id": "0d4ff136"
      },
      "outputs": [],
      "source": [
        "def solve_fine(spe10, pos_well, injection_rate=1, well_pressure=0, export_folder=None):\n",
        "    \"\"\"\n",
        "    Compute the averaged gradient and flux for a given subdomain and direction of the pressure\n",
        "    gradient.\n",
        "\n",
        "    Args:\n",
        "        spe10 (object): The object representing the subdomain.\n",
        "        pos_well (np.ndarray): The position of the production well.\n",
        "        injection_rate (float, optional): The injection rate of the wells. Defaults to 1.\n",
        "        well_pressure (float, optional): The pressure at the production well. Defaults to 0.\n",
        "        export_folder (str, optional): If given, path where to export the results. Defaults to\n",
        "            None.\n",
        "\n",
        "    Returns:\n",
        "        float: The maximum pressure at the injection wells.\n",
        "    \"\"\"\n",
        "    # Extract the grid for simplicity\n",
        "    sd = spe10.sd\n",
        "    perm_dict = spe10.perm_as_dict()\n",
        "\n",
        "    # Permeability\n",
        "    perm_tensor = pp.SecondOrderTensor(kxx=perm_dict[\"kxx\"])\n",
        "    #print(perm_tensor)\n",
        "\n",
        "    # Boundary conditions\n",
        "    b_faces = sd.tags[\"domain_boundary_faces\"].nonzero()[0]\n",
        "\n",
        "    # Define the labels and values for the boundary faces\n",
        "    labels = np.array([\"neu\"] * b_faces.size)\n",
        "    bc_val = np.zeros(sd.num_faces)\n",
        "    bc = pp.BoundaryCondition(sd, b_faces, labels)\n",
        "\n",
        "    # Collect all parameters in a dictionary\n",
        "    key = \"flow\"\n",
        "    parameters = {\"second_order_tensor\": perm_tensor, \"bc\": bc, \"bc_values\": bc_val}\n",
        "    data = pp.initialize_default_data(sd, {}, key, parameters)\n",
        "\n",
        "    # Discretize the problem\n",
        "    discr = pp.Mpfa(key)\n",
        "    discr.discretize(sd, data)\n",
        "\n",
        "    A, b = discr.assemble_matrix_rhs(sd, data)\n",
        "\n",
        "    # Add the injection wells, all with the same injection rate\n",
        "    b_wells = np.zeros_like(b)\n",
        "    index_iwells = [\n",
        "        0,\n",
        "        spe10.full_shape[0] - 1,\n",
        "        spe10.full_shape[0] * spe10.full_shape[1] - spe10.full_shape[0],\n",
        "        spe10.full_shape[0] * spe10.full_shape[1] - 1,\n",
        "    ]\n",
        "    b_wells[index_iwells] = injection_rate\n",
        "\n",
        "    # Add the production well by using a Lagrange multiplier, first we identify the cell\n",
        "    ij_well = np.floor((np.asarray(pos_well) / spe10.spacing[:-1])).astype(int)\n",
        "    print(ij_well)\n",
        "    index_pwell = spe10.full_shape[0] * ij_well[1] + ij_well[0]\n",
        "    vect = np.zeros((sd.num_cells, 1))\n",
        "    vect[index_pwell] = 1\n",
        "\n",
        "    # Solve the linear system and compute the pressure by adding the constraint\n",
        "    A = sps.bmat([[A, vect], [vect.T, None]], format=\"csc\")\n",
        "    b = np.append(b + b_wells, well_pressure)\n",
        "    p = sps.linalg.spsolve(A, b)[:-1]\n",
        "\n",
        "    # extract the discretization matrices build\n",
        "    mat_discr = data[pp.DISCRETIZATION_MATRICES][key]\n",
        "\n",
        "    # reconstruct the flux as post-process\n",
        "    q_tpfa = mat_discr[\"flux\"] @ p + mat_discr[\"bound_flux\"] @ bc_val\n",
        "\n",
        "    # to export the flux\n",
        "    mvem = pp.MVEM(key)\n",
        "    mvem.discretize(sd, data)\n",
        "    # construct the P0 flux reconstruction\n",
        "    cell_q_mpfa = mvem.project_flux(sd, q_tpfa, data)\n",
        "\n",
        "\n",
        "    # Export the solution\n",
        "    if export_folder is not None:\n",
        "        save = pp.Exporter(sd, \"sol\", folder_name=export_folder)\n",
        "        save.write_vtu([(\"p\", p), (\"log_kxx\", np.log10(perm_dict[\"kxx\"])),(\"q_mpfa\", cell_q_mpfa)])\n",
        "\n",
        "    # Return the maximum pressure at the injection wells\n",
        "    return np.max(p[index_iwells])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def upscale(sd, perm, dir, export_folder=None):\n",
        "    \"\"\"\n",
        "    Compute the averaged gradient and flux for a given subdomain and direction of the pressure\n",
        "    gradient.\n",
        "\n",
        "    Args:\n",
        "        sd (pp.Grid): The grid representing the subdomain.\n",
        "        perm (dict): The permeability of the subdomain divided in the fields \"kxx\" and \"kyy\"\n",
        "        dir (int): The direction of the flow, 0 means x-direction and 1 means y-direction.\n",
        "        export_folder (str): If given, path where to export the results.\n",
        "            Default to None, no exporting.\n",
        "\n",
        "    Returns:\n",
        "        (np.ndarray, np.ndarray): averaged gradient and flux.\n",
        "    \"\"\"\n",
        "    # Permeability\n",
        "    perm_tensor = pp.SecondOrderTensor(kxx=perm[\"kxx\"], kyy=perm[\"kyy\"])\n",
        "\n",
        "    # Boundary conditions\n",
        "    b_faces = sd.tags[\"domain_boundary_faces\"].nonzero()[0]\n",
        "    b_face_centers = sd.face_centers[:, b_faces]\n",
        "\n",
        "    # Find the min and max values of the boundary faces\n",
        "    sd_min = np.amin(sd.face_centers[dir, :])\n",
        "    sd_max = np.amax(sd.face_centers[dir, :])\n",
        "\n",
        "    # define outflow and inflow type boundary conditions\n",
        "    out_flow = np.isclose(b_face_centers[dir, :], sd_max)\n",
        "    in_flow = np.isclose(b_face_centers[dir, :], sd_min)\n",
        "\n",
        "    # define the labels and values for the boundary faces\n",
        "    labels = np.array([\"neu\"] * b_faces.size)\n",
        "    labels[np.logical_or(in_flow, out_flow)] = \"dir\"\n",
        "\n",
        "    bc_val = np.zeros(sd.num_faces)\n",
        "    bc_val[b_faces[in_flow]] = sd_max - sd_min\n",
        "\n",
        "    bc = pp.BoundaryCondition(sd, b_faces, labels)\n",
        "\n",
        "    # Collect all parameters in a dictionary\n",
        "    key = \"flow\"\n",
        "    parameters = {\"second_order_tensor\": perm_tensor, \"bc\": bc, \"bc_values\": bc_val}\n",
        "    data = pp.initialize_default_data(sd, {}, key, parameters)\n",
        "\n",
        "    # Discretize the problem (construct the lhr and rhs)\n",
        "    discr = pp.Tpfa(key)\n",
        "    discr.discretize(sd, data)\n",
        "\n",
        "    A, b = discr.assemble_matrix_rhs(sd, data)\n",
        "\n",
        "    # Solve the linear system and compute the pressure\n",
        "    p = sps.linalg.spsolve(A, b)\n",
        "\n",
        "    # Export the solution\n",
        "    if export_folder is not None:\n",
        "        save = pp.Exporter(sd, \"sol\", folder_name=export_folder)\n",
        "        save.write_vtu([(\"p\", p), (\"log_perm\", np.log10(perm[\"kxx\"]))])\n",
        "\n",
        "    # Post-process the solution to get the flux\n",
        "    return compute_avg_q_grad(sd, p, data, key, bc, bc_val)"
      ],
      "metadata": {
        "id": "Q4p-yhCCvmR7"
      },
      "id": "Q4p-yhCCvmR7",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_tensor(grad_h, grad_v, q_h, q_v):\n",
        "    \"\"\"\n",
        "    Compute the upscaled permeability tensor.\n",
        "\n",
        "    Args:\n",
        "        grad_h (np.ndarray): Gradient in the horizontal direction.\n",
        "        grad_v (np.ndarray): Gradient in the vertical direction.\n",
        "        q_h (np.ndarray): Flux in the horizontal direction.\n",
        "        q_v (np.ndarray): Flux in the vertical direction.\n",
        "\n",
        "    Returns:\n",
        "        perm (np.ndarray): Upscaled permeability tensor.\n",
        "\n",
        "    The function solves a linear system to obtain the upscaled permeability tensor\n",
        "    based on the given gradients and fluxes. It enforces numerical symmetry and\n",
        "    checks if the resulting tensor is symmetric positive definite (SPD).\n",
        "    \"\"\"\n",
        "    # Solve the linear system to get the upscaled permeability\n",
        "    lhs = np.array([\n",
        "        [grad_h[0], grad_h[1], 0, 0],\n",
        "        [0, 0, grad_h[0], grad_h[1]],\n",
        "        [grad_v[0], grad_v[1], 0, 0],\n",
        "        [0, 0, grad_v[0], grad_v[1]],\n",
        "        [0, 1, -1, 0]\n",
        "    ])\n",
        "\n",
        "    rhs = np.array([q_h[0], q_h[1], q_v[0], q_v[1], 0])\n",
        "\n",
        "    perm = np.linalg.lstsq(lhs, rhs, rcond=None)[0]\n",
        "\n",
        "    # make it symmetric positive definite\n",
        "    perm = nearest_spd(perm.reshape(2, 2)).ravel()\n",
        "\n",
        "    return perm"
      ],
      "metadata": {
        "id": "DA4gjqYcvrWs"
      },
      "id": "DA4gjqYcvrWs",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_subdomain(sub_sd_id, sub_sd, perm_dict, folder_results, part, kxx_up, kxy_up, kyx_up, kyy_up):\n",
        "    mask = part == sub_sd_id\n",
        "    sub_perm = {key: val[mask] for key, val in perm_dict.items()}\n",
        "\n",
        "    folder_x = folder_results + str(sub_sd_id) + \"_x\"\n",
        "    q_h, grad_h = upscale(sub_sd, sub_perm, 0, folder_x)\n",
        "\n",
        "    folder_y = folder_results + str(sub_sd_id) + \"_y\"\n",
        "    q_v, grad_v = upscale(sub_sd, sub_perm, 1, folder_y)\n",
        "\n",
        "    kk = compute_tensor(grad_h, grad_v, q_h, q_v)\n",
        "\n",
        "    return [kk[0], kk[1], kk[2], kk[3]]\n",
        "\n",
        "def Checkpoint1_solution(selected_layers, folder_results):\n",
        "    spe10 = Spe10(selected_layers)\n",
        "    perm_folder = spe10_folder + \"/perm/\"\n",
        "    spe10.read_perm(perm_folder)\n",
        "    perm_dict = spe10.perm_as_dict()\n",
        "\n",
        "    num_part = 100\n",
        "    part, sub_sds, sd_coarse = coarse_grid(spe10.sd, num_part)\n",
        "\n",
        "    kxx_up = np.zeros(spe10.sd.num_cells)\n",
        "    kxy_up = np.zeros(spe10.sd.num_cells)\n",
        "    kyx_up = np.zeros(spe10.sd.num_cells)\n",
        "    kyy_up = np.zeros(spe10.sd.num_cells)\n",
        "    kxx = np.zeros(spe10.sd.num_cells)\n",
        "\n",
        "    pool = multiprocessing.Pool(processes=multiprocessing.cpu_count())\n",
        "    result = pool.starmap_async(process_subdomain, [(sub_sd_id, sub_sd, perm_dict, folder_results, part, kxx_up, kxy_up, kyx_up, kyy_up) for sub_sd_id, sub_sd in enumerate(sub_sds)]).get()\n",
        "\n",
        "    for sub_sd_id, kk in enumerate(result):\n",
        "        mask = part == sub_sd_id\n",
        "        sub_perm = {key: val[mask] for key, val in perm_dict.items()}\n",
        "        kxx[mask] = sub_perm[\"kxx\"]\n",
        "        kxx_up[mask], kxy_up[mask], kyx_up[mask], kyy_up[mask] = kk\n",
        "        #print(f\"Subdomain {sub_sd_id}: {kk}\")\n",
        "\n",
        "    var_to_save = [\n",
        "        (\"kxx\", np.log10(kxx_up)),\n",
        "        (\"kxy\", kxy_up),\n",
        "        (\"kyx\", kyx_up),\n",
        "        (\"kyy\", np.log10(kyy_up)),\n",
        "        (\"fine\", np.log10(kxx))\n",
        "    ]\n",
        "\n",
        "    save = pp.Exporter(spe10.sd, \"upscaled_k\", folder_name=folder_results)\n",
        "    save.write_vtu(var_to_save)\n",
        "\n",
        "    write_upscaled_perm(\"as_tensor\", sd_coarse, result, folder_results)\n",
        "\n",
        "    return sd_coarse, result"
      ],
      "metadata": {
        "id": "vnUm6muuJJR7"
      },
      "id": "vnUm6muuJJR7",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "roman-glossary",
      "metadata": {
        "id": "roman-glossary"
      },
      "source": [
        "Define the function that given a subdomain, its data, and a direction compute the upscaled gradient and flux."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "41d2d511",
      "metadata": {
        "id": "41d2d511"
      },
      "outputs": [],
      "source": [
        "def solve_coarse(\n",
        "    sd,\n",
        "    pos_well,\n",
        "    kk,\n",
        "    injection_rate=1,\n",
        "    well_pressure=0,\n",
        "    export_folder=None,\n",
        "):\n",
        "    \"\"\"\n",
        "    Compute the averaged gradient and flux for a given subdomain and direction of the pressure\n",
        "    gradient.\n",
        "\n",
        "    Args:\n",
        "        spe10 (object): The object representing the subdomain.\n",
        "        pos_well (np.ndarray): The position of the production well.\n",
        "        injection_rate (float, optional): The injection rate of the wells. Defaults to 1.\n",
        "        well_pressure (float, optional): The pressure at the production well. Defaults to 0.\n",
        "        export_folder (str, optional): If given, path where to export the results. Defaults to\n",
        "            None.\n",
        "\n",
        "    Returns:\n",
        "        float: The maximum pressure at the injection wells.\n",
        "    \"\"\"\n",
        "\n",
        "    # Permeability\n",
        "    result = np.array(kk).T\n",
        "    perm_tensor = pp.SecondOrderTensor(kxx=result[0], kyy=result[3], kxy=result[1])\n",
        "    #print(perm_tensor)\n",
        "\n",
        "    # Boundary conditions\n",
        "    b_faces = sd.tags[\"domain_boundary_faces\"].nonzero()[0]\n",
        "\n",
        "    # Define the labels and values for the boundary faces\n",
        "    labels = np.array([\"neu\"] * b_faces.size)\n",
        "    bc_val = np.zeros(sd.num_faces)\n",
        "    bc = pp.BoundaryCondition(sd, b_faces, labels)\n",
        "\n",
        "    # Collect all parameters in a dictionary\n",
        "\n",
        "    key = \"flow\"\n",
        "    parameters = {\"second_order_tensor\": perm_tensor, \"bc\": bc, \"bc_values\": bc_val}\n",
        "    data = pp.initialize_default_data(sd, {}, key, parameters)\n",
        "\n",
        "    # Discretize the problem\n",
        "    discr = pp.Mpfa(key)\n",
        "    discr.discretize(sd, data)\n",
        "\n",
        "    A, b = discr.assemble_matrix_rhs(sd, data)\n",
        "\n",
        "    #properties of the grid\n",
        "    ncomp_x = 10\n",
        "    ncomp_y = 10\n",
        "    len_x = 365.76\n",
        "    len_y = 670.56\n",
        "    spacing = np.array([len_x / ncomp_x, len_y / ncomp_y])\n",
        "\n",
        "    # Add the injection wells, all with the same injection rate\n",
        "    b_wells = np.zeros_like(b)\n",
        "    index_iwells = [\n",
        "        0,\n",
        "        ncomp_x - 1,\n",
        "        ncomp_x * ncomp_y - ncomp_x,\n",
        "        ncomp_x * ncomp_y - 1,\n",
        "    ]\n",
        "    b_wells[index_iwells] = injection_rate\n",
        "\n",
        "    # Add the production well by using a Lagrange multiplier, first we identify the cell\n",
        "    ij_well = np.floor((np.asarray(pos_well) / spacing)).astype(int)\n",
        "    print(ij_well)\n",
        "    index_pwell = ncomp_x * ij_well[1] + ij_well[0]\n",
        "    vect = np.zeros((sd.num_cells, 1))\n",
        "    vect[index_pwell] = 1\n",
        "\n",
        "    # Solve the linear system and compute the pressure by adding the constraint\n",
        "    A = sps.bmat([[A, vect], [vect.T, None]], format=\"csc\")\n",
        "    b = np.append(b + b_wells, well_pressure)\n",
        "    p = sps.linalg.spsolve(A, b)[:-1]\n",
        "\n",
        "    # extract the discretization matrices build\n",
        "    mat_discr = data[pp.DISCRETIZATION_MATRICES][key]\n",
        "\n",
        "    # reconstruct the flux as post-process\n",
        "    q_tpfa = mat_discr[\"flux\"] @ p + mat_discr[\"bound_flux\"] @ bc_val\n",
        "\n",
        "    # to export the flux\n",
        "    mvem = pp.MVEM(key)\n",
        "    mvem.discretize(sd, data)\n",
        "    # construct the P0 flux reconstruction\n",
        "    cell_q_mpfa = mvem.project_flux(sd, q_tpfa, data)\n",
        "\n",
        "\n",
        "    # Export the solution\n",
        "    if export_folder is not None:\n",
        "        save = pp.Exporter(sd, \"sol\", folder_name=export_folder)\n",
        "        save.write_vtu([(\"p\", p), (\"log_kxx\", np.log10(result[0])),(\"q_mpfa\", cell_q_mpfa)])\n",
        "\n",
        "    # Return the maximum pressure at the injection wells\n",
        "    return np.max(p[index_iwells])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "precious-belle",
      "metadata": {
        "id": "precious-belle"
      },
      "source": [
        "Perform the evaluation of the functional for the Spe10 benchmark of a given layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "spare-person",
      "metadata": {
        "id": "spare-person",
        "outputId": "f4ae533f-8aff-4b16-db67-71f40488228d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[6 7]\n",
            "0.9348684156141392\n",
            "[ 37 157]\n",
            "4.379623119819391\n"
          ]
        }
      ],
      "source": [
        "selected_layers = 20\n",
        "folder_results = main_folder + \"results/\"\n",
        "\n",
        "# Read the SPE10 grid\n",
        "spe10 = Spe10(selected_layers)\n",
        "\n",
        "# Read the permeability associated to the given layer(s)\n",
        "perm_folder = spe10_folder + \"/perm/\"\n",
        "spe10.read_perm(perm_folder)\n",
        "\n",
        "# Read the permeability associated to the given layer(s) for coarse grid\n",
        "sd_coarse, result = Checkpoint1_solution(selected_layers, folder_results)\n",
        "\n",
        "# Define the function to evaluate that depends only on the position of the injection well\n",
        "CostFunctional = lambda x: solve_coarse(\n",
        "    sd_coarse, x, result, export_folder=folder_results\n",
        ")\n",
        "\n",
        "CostFunctionalFine = lambda x: solve_fine(\n",
        "    spe10, x, export_folder=folder_results\n",
        ")\n",
        "\n",
        "print(CostFunctional([231, 481]))\n",
        "print(CostFunctionalFine([231, 481]))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "25631b9b",
      "metadata": {
        "id": "25631b9b"
      },
      "source": [
        "# Optimization"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ncomp_x = 10\n",
        "ncomp_y = 10\n",
        "len_x = 365.76\n",
        "len_y = 670.56\n",
        "spacing = np.array([len_x / ncomp_x, len_y / ncomp_y])\n",
        "starting_point_x = spacing[0] / 2 + spacing[0] * np.arange(10)\n",
        "starting_point_y = spacing[1] / 2 + spacing[1] * np.arange(10)\n",
        "\n",
        "grid_points = []\n",
        "for x in starting_point_x:\n",
        "    for y in starting_point_y:\n",
        "        grid_points.append((x, y))\n",
        "\n",
        "grid_points = np.array(grid_points)"
      ],
      "metadata": {
        "id": "w_bgPNKgOwSK"
      },
      "id": "w_bgPNKgOwSK",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "48fdd2f3",
      "metadata": {
        "id": "48fdd2f3"
      },
      "outputs": [],
      "source": [
        "def checkpoint2_solution(selected_layers, folder_results):\n",
        "\n",
        "    # Read the SPE10 grid\n",
        "    spe10 = Spe10(selected_layers)\n",
        "\n",
        "    # define cost functional on coarse scale (note that it depends on the upscaling)\n",
        "    CostFunctional = lambda x: solve_coarse(sd_coarse, x, result, export_folder = folder_results)\n",
        "\n",
        "    # define cost functional on fine scale\n",
        "    CostFunctionalFine = lambda x: solve_fine(spe10, x, export_folder = folder_results)\n",
        "\n",
        "    # starting point\n",
        "    mu_guess = [\n",
        "        (spe10.full_physdims[0]) / 2.0,\n",
        "        (spe10.full_physdims[1]) / 2.0,\n",
        "    ]\n",
        "\n",
        "    # TODO using both solve_corse and solve_fine\n",
        "    loss_old = float('inf')\n",
        "    best_k = 0\n",
        "\n",
        "    for k in range(len(grid_points)):\n",
        "      print(f'Iteration {k} / 100')\n",
        "      loss = CostFunctional(grid_points[k])\n",
        "      if loss < loss_old:\n",
        "        mu_est = grid_points[k]\n",
        "        loss_old = loss\n",
        "        best_k = k\n",
        "        print('Updated best position')\n",
        "      print()\n",
        "\n",
        "    best_ij = np.floor((np.asarray(grid_points[best_k]) / spacing)).astype(int) #retrieving poswell inidices\n",
        "    print(f'Best position at {mu_est} at position {best_ij} of the coarse grid')\n",
        "\n",
        "    return mu_est"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "well_est = checkpoint2_solution(selected_layers, folder_results)"
      ],
      "metadata": {
        "id": "9OnCm9x6C1CL",
        "outputId": "f3e4c1a7-97e0-429e-94b1-6d121bf6eaca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "9OnCm9x6C1CL",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 0 / 100\n",
            "[0 0]\n",
            "Updated best position\n",
            "\n",
            "Iteration 1 / 100\n",
            "[0 1]\n",
            "Updated best position\n",
            "\n",
            "Iteration 2 / 100\n",
            "[0 2]\n",
            "Updated best position\n",
            "\n",
            "Iteration 3 / 100\n",
            "[0 3]\n",
            "\n",
            "Iteration 4 / 100\n",
            "[0 4]\n",
            "\n",
            "Iteration 5 / 100\n",
            "[0 5]\n",
            "\n",
            "Iteration 6 / 100\n",
            "[0 6]\n",
            "\n",
            "Iteration 7 / 100\n",
            "[0 7]\n",
            "\n",
            "Iteration 8 / 100\n",
            "[0 8]\n",
            "\n",
            "Iteration 9 / 100\n",
            "[0 9]\n",
            "\n",
            "Iteration 10 / 100\n",
            "[1 0]\n",
            "\n",
            "Iteration 11 / 100\n",
            "[1 1]\n",
            "Updated best position\n",
            "\n",
            "Iteration 12 / 100\n",
            "[1 2]\n",
            "Updated best position\n",
            "\n",
            "Iteration 13 / 100\n",
            "[1 3]\n",
            "\n",
            "Iteration 14 / 100\n",
            "[1 4]\n",
            "\n",
            "Iteration 15 / 100\n",
            "[1 5]\n",
            "\n",
            "Iteration 16 / 100\n",
            "[1 6]\n",
            "\n",
            "Iteration 17 / 100\n",
            "[1 7]\n",
            "\n",
            "Iteration 18 / 100\n",
            "[1 8]\n",
            "\n",
            "Iteration 19 / 100\n",
            "[1 9]\n",
            "\n",
            "Iteration 20 / 100\n",
            "[2 0]\n",
            "\n",
            "Iteration 21 / 100\n",
            "[2 1]\n",
            "Updated best position\n",
            "\n",
            "Iteration 22 / 100\n",
            "[2 2]\n",
            "Updated best position\n",
            "\n",
            "Iteration 23 / 100\n",
            "[2 3]\n",
            "\n",
            "Iteration 24 / 100\n",
            "[2 4]\n",
            "\n",
            "Iteration 25 / 100\n",
            "[2 5]\n",
            "\n",
            "Iteration 26 / 100\n",
            "[2 6]\n",
            "\n",
            "Iteration 27 / 100\n",
            "[2 7]\n",
            "\n",
            "Iteration 28 / 100\n",
            "[2 8]\n",
            "\n",
            "Iteration 29 / 100\n",
            "[2 9]\n",
            "\n",
            "Iteration 30 / 100\n",
            "[3 0]\n",
            "\n",
            "Iteration 31 / 100\n",
            "[3 1]\n",
            "\n",
            "Iteration 32 / 100\n",
            "[3 2]\n",
            "Updated best position\n",
            "\n",
            "Iteration 33 / 100\n",
            "[3 3]\n",
            "\n",
            "Iteration 34 / 100\n",
            "[3 4]\n",
            "\n",
            "Iteration 35 / 100\n",
            "[3 5]\n",
            "\n",
            "Iteration 36 / 100\n",
            "[3 6]\n",
            "\n",
            "Iteration 37 / 100\n",
            "[3 7]\n",
            "\n",
            "Iteration 38 / 100\n",
            "[3 8]\n",
            "\n",
            "Iteration 39 / 100\n",
            "[3 9]\n",
            "\n",
            "Iteration 40 / 100\n",
            "[4 0]\n",
            "\n",
            "Iteration 41 / 100\n",
            "[4 1]\n",
            "\n",
            "Iteration 42 / 100\n",
            "[4 2]\n",
            "Updated best position\n",
            "\n",
            "Iteration 43 / 100\n",
            "[4 3]\n",
            "\n",
            "Iteration 44 / 100\n",
            "[4 4]\n",
            "\n",
            "Iteration 45 / 100\n",
            "[4 5]\n",
            "\n",
            "Iteration 46 / 100\n",
            "[4 6]\n",
            "\n",
            "Iteration 47 / 100\n",
            "[4 7]\n",
            "\n",
            "Iteration 48 / 100\n",
            "[4 8]\n",
            "\n",
            "Iteration 49 / 100\n",
            "[4 9]\n",
            "\n",
            "Iteration 50 / 100\n",
            "[5 0]\n",
            "\n",
            "Iteration 51 / 100\n",
            "[5 1]\n",
            "\n",
            "Iteration 52 / 100\n",
            "[5 2]\n",
            "\n",
            "Iteration 53 / 100\n",
            "[5 3]\n",
            "\n",
            "Iteration 54 / 100\n",
            "[5 4]\n",
            "\n",
            "Iteration 55 / 100\n",
            "[5 5]\n",
            "\n",
            "Iteration 56 / 100\n",
            "[5 6]\n",
            "\n",
            "Iteration 57 / 100\n",
            "[5 7]\n",
            "\n",
            "Iteration 58 / 100\n",
            "[5 8]\n",
            "\n",
            "Iteration 59 / 100\n",
            "[5 9]\n",
            "\n",
            "Iteration 60 / 100\n",
            "[6 0]\n",
            "\n",
            "Iteration 61 / 100\n",
            "[6 1]\n",
            "\n",
            "Iteration 62 / 100\n",
            "[6 2]\n",
            "\n",
            "Iteration 63 / 100\n",
            "[6 3]\n",
            "\n",
            "Iteration 64 / 100\n",
            "[6 4]\n",
            "\n",
            "Iteration 65 / 100\n",
            "[6 5]\n",
            "\n",
            "Iteration 66 / 100\n",
            "[6 6]\n",
            "\n",
            "Iteration 67 / 100\n",
            "[6 7]\n",
            "\n",
            "Iteration 68 / 100\n",
            "[6 8]\n",
            "\n",
            "Iteration 69 / 100\n",
            "[6 9]\n",
            "\n",
            "Iteration 70 / 100\n",
            "[7 0]\n",
            "\n",
            "Iteration 71 / 100\n",
            "[7 1]\n",
            "\n",
            "Iteration 72 / 100\n",
            "[7 2]\n",
            "\n",
            "Iteration 73 / 100\n",
            "[7 3]\n",
            "\n",
            "Iteration 74 / 100\n",
            "[7 4]\n",
            "\n",
            "Iteration 75 / 100\n",
            "[7 5]\n",
            "\n",
            "Iteration 76 / 100\n",
            "[7 6]\n",
            "\n",
            "Iteration 77 / 100\n",
            "[7 7]\n",
            "\n",
            "Iteration 78 / 100\n",
            "[7 8]\n",
            "\n",
            "Iteration 79 / 100\n",
            "[7 9]\n",
            "\n",
            "Iteration 80 / 100\n",
            "[8 0]\n",
            "\n",
            "Iteration 81 / 100\n",
            "[8 1]\n",
            "\n",
            "Iteration 82 / 100\n",
            "[8 2]\n",
            "\n",
            "Iteration 83 / 100\n",
            "[8 3]\n",
            "\n",
            "Iteration 84 / 100\n",
            "[8 4]\n",
            "\n",
            "Iteration 85 / 100\n",
            "[8 5]\n",
            "\n",
            "Iteration 86 / 100\n",
            "[8 6]\n",
            "\n",
            "Iteration 87 / 100\n",
            "[8 7]\n",
            "\n",
            "Iteration 88 / 100\n",
            "[8 8]\n",
            "\n",
            "Iteration 89 / 100\n",
            "[8 9]\n",
            "\n",
            "Iteration 90 / 100\n",
            "[9 0]\n",
            "\n",
            "Iteration 91 / 100\n",
            "[9 1]\n",
            "\n",
            "Iteration 92 / 100\n",
            "[9 2]\n",
            "\n",
            "Iteration 93 / 100\n",
            "[9 3]\n",
            "\n",
            "Iteration 94 / 100\n",
            "[9 4]\n",
            "\n",
            "Iteration 95 / 100\n",
            "[9 5]\n",
            "\n",
            "Iteration 96 / 100\n",
            "[9 6]\n",
            "\n",
            "Iteration 97 / 100\n",
            "[9 7]\n",
            "\n",
            "Iteration 98 / 100\n",
            "[9 8]\n",
            "\n",
            "Iteration 99 / 100\n",
            "[9 9]\n",
            "\n",
            "Best position at [164.592 167.64 ] at position [4 2] of the coarse grid\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    },
    "vscode": {
      "interpreter": {
        "hash": "e4cc1db98167c7fd7d55a1da8057731abc6cd6fe154328a2ae319df8aab4e24d"
      }
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}