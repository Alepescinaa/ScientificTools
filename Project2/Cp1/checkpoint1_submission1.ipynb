{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import porepy as pp\n",
        "import scipy.sparse as sps\n",
        "import scipy\n",
        "import sys"
      ],
      "metadata": {
        "id": "S-wdakT1Bf8s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82a9551c-d143-4896-c350-70b24800306a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/porepy/numerics/nonlinear/nonlinear_solvers.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
            "  from tqdm.autonotebook import trange  # type: ignore\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "main_folder = \"./\"\n",
        "spe10_folder = main_folder + \"spe10\"\n",
        "sys.path.insert(1, spe10_folder)\n",
        "\n",
        "from functions import *\n",
        "from spe10 import Spe10"
      ],
      "metadata": {
        "id": "b2nJ0k6MBhR_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def upscale(sd, perm, dir, export_folder=None):\n",
        "    \"\"\"\n",
        "    Compute the averaged gradient and flux for a given subdomain and direction of the pressure\n",
        "    gradient.\n",
        "\n",
        "    Args:\n",
        "        sd (pp.Grid): The grid representing the subdomain.\n",
        "        perm (dict): The permeability of the subdomain divided in the fields \"kxx\" and \"kyy\"\n",
        "        dir (int): The direction of the flow, 0 means x-direction and 1 means y-direction.\n",
        "        export_folder (str): If given, path where to export the results.\n",
        "            Default to None, no exporting.\n",
        "\n",
        "    Returns:\n",
        "        (np.ndarray, np.ndarray): averaged gradient and flux.\n",
        "    \"\"\"\n",
        "    # Permeability\n",
        "    perm_tensor = pp.SecondOrderTensor(kxx=perm[\"kxx\"], kyy=perm[\"kyy\"])\n",
        "\n",
        "    # Boundary conditions\n",
        "    b_faces = sd.tags[\"domain_boundary_faces\"].nonzero()[0]\n",
        "    b_face_centers = sd.face_centers[:, b_faces]\n",
        "\n",
        "    # Find the min and max values of the boundary faces\n",
        "    sd_min = np.amin(sd.face_centers[dir, :])\n",
        "    sd_max = np.amax(sd.face_centers[dir, :])\n",
        "\n",
        "    # define outflow and inflow type boundary conditions\n",
        "    out_flow = np.isclose(b_face_centers[dir, :], sd_max)\n",
        "    in_flow = np.isclose(b_face_centers[dir, :], sd_min)\n",
        "\n",
        "    # define the labels and values for the boundary faces\n",
        "    labels = np.array([\"neu\"] * b_faces.size)\n",
        "    labels[np.logical_or(in_flow, out_flow)] = \"dir\"\n",
        "\n",
        "    bc_val = np.zeros(sd.num_faces)\n",
        "    bc_val[b_faces[in_flow]] = sd_max - sd_min\n",
        "\n",
        "    bc = pp.BoundaryCondition(sd, b_faces, labels)\n",
        "\n",
        "    # Collect all parameters in a dictionary\n",
        "    key = \"flow\"\n",
        "    parameters = {\"second_order_tensor\": perm_tensor, \"bc\": bc, \"bc_values\": bc_val}\n",
        "    data = pp.initialize_default_data(sd, {}, key, parameters)\n",
        "\n",
        "    # Discretize the problem (construct the lhr and rhs)\n",
        "    #discr = TODO\n",
        "    #discr.discretize TODO\n",
        "    discr = pp.Mpfa(key)\n",
        "    discr.discretize(sd, data)\n",
        "\n",
        "    #A, b = TODO\n",
        "    A, b = discr.assemble_matrix_rhs(sd, data)\n",
        "\n",
        "    # Solve the linear system and compute the pressure\n",
        "    # p = TODO\n",
        "    p = sps.linalg.spsolve(A, b)\n",
        "\n",
        "    # Export the solution\n",
        "    if export_folder is not None:\n",
        "        save = pp.Exporter(sd, \"sol\", folder_name=export_folder)\n",
        "        save.write_vtu([(\"p\", p), (\"log_perm\", np.log10(perm[\"kxx\"]))])\n",
        "\n",
        "    # Post-process the solution to get the flux\n",
        "    return compute_avg_q_grad(sd, p, data, key, bc, bc_val)"
      ],
      "metadata": {
        "id": "Dim-F_cYBiqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_tensor(grad_h, grad_v, q_h, q_v):\n",
        "    \"\"\"\n",
        "    Compute the upscaled permeability tensor.\n",
        "\n",
        "    Args:\n",
        "        grad_h (np.ndarray): Gradient in the horizontal direction.\n",
        "        grad_v (np.ndarray): Gradient in the vertical direction.\n",
        "        q_h (np.ndarray): Flux in the horizontal direction.\n",
        "        q_v (np.ndarray): Flux in the vertical direction.\n",
        "\n",
        "    Returns:\n",
        "        perm (np.ndarray): Upscaled permeability tensor.\n",
        "\n",
        "    The function solves a linear system to obtain the upscaled permeability tensor\n",
        "    based on the given gradients and fluxes. It enforces numerical symmetry and\n",
        "    checks if the resulting tensor is symmetric positive definite (SPD).\n",
        "    \"\"\"\n",
        "    # Solve the linear system to get the upscaled permeability\n",
        "    # TODO\n",
        "    lhs = np.array([\n",
        "        [grad_h[0], grad_h[1], 0, 0],\n",
        "        [0, 0, grad_h[0], grad_h[1]],\n",
        "        [grad_v[0], grad_v[1], 0, 0],\n",
        "        [0, 0, grad_v[0], grad_v[1]],\n",
        "        [0, 1, -1, 0]\n",
        "    ])\n",
        "\n",
        "    rhs = np.array([q_h[0], q_h[1], q_v[0], q_v[1], 0])\n",
        "\n",
        "    perm = np.linalg.lstsq(lhs, rhs, rcond=None)[0]\n",
        "\n",
        "    # make it symmetric positive definite\n",
        "    perm = nearest_spd(perm.reshape(2, 2)).ravel()\n",
        "\n",
        "    return perm"
      ],
      "metadata": {
        "id": "Tt4EtGa6BkCq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import multiprocessing\n",
        "\n",
        "def process_subdomain(sub_sd_id, sub_sd, perm_dict, folder_results, part, kxx_up, kxy_up, kyx_up, kyy_up):\n",
        "    mask = part == sub_sd_id\n",
        "    sub_perm = {key: val[mask] for key, val in perm_dict.items()}\n",
        "\n",
        "    folder_x = folder_results + str(sub_sd_id) + \"_x\"\n",
        "    q_h, grad_h = upscale(sub_sd, sub_perm, 0, folder_x)\n",
        "\n",
        "    folder_y = folder_results + str(sub_sd_id) + \"_y\"\n",
        "    q_v, grad_v = upscale(sub_sd, sub_perm, 1, folder_y)\n",
        "\n",
        "    kk = compute_tensor(grad_h, grad_v, q_h, q_v)\n",
        "\n",
        "    return [kk[0], kk[1], kk[2], kk[3]]\n",
        "\n",
        "def Checkpoint1_solution(selected_layers, folder_results):\n",
        "    spe10 = Spe10(selected_layers)\n",
        "    perm_folder = spe10_folder + \"/perm/\"\n",
        "    spe10.read_perm(perm_folder)\n",
        "    perm_dict = spe10.perm_as_dict()\n",
        "\n",
        "    num_part = 20\n",
        "    part, sub_sds, sd_coarse = coarse_grid(spe10.sd, num_part)\n",
        "\n",
        "    kxx_up = np.zeros(spe10.sd.num_cells)\n",
        "    kxy_up = np.zeros(spe10.sd.num_cells)\n",
        "    kyx_up = np.zeros(spe10.sd.num_cells)\n",
        "    kyy_up = np.zeros(spe10.sd.num_cells)\n",
        "    kxx = np.zeros(spe10.sd.num_cells)\n",
        "\n",
        "    process = multiprocessing.Pool(processes = 8)\n",
        "    result = process.starmap(process_subdomain, [(sub_sd_id, sub_sd, perm_dict, folder_results, part, kxx_up, kxy_up, kyx_up, kyy_up) for sub_sd_id, sub_sd in enumerate(sub_sds)])\n",
        "    process.close()\n",
        "    process.join()\n",
        "\n",
        "    for sub_sd_id, kk in enumerate(result):\n",
        "        mask = part == sub_sd_id\n",
        "        sub_perm = {key: val[mask] for key, val in perm_dict.items()}\n",
        "        kxx[mask] = sub_perm[\"kxx\"]\n",
        "        kxx_up[mask], kxy_up[mask], kyx_up[mask], kyy_up[mask] = kk\n",
        "        print(f\"Subdomain {sub_sd_id}: {kk}\")\n",
        "\n",
        "    var_to_save = [\n",
        "        (\"kxx\", kxx_up),\n",
        "        (\"kxy\", kxy_up),\n",
        "        (\"kyx\", kyx_up),\n",
        "        (\"kyy\", kyy_up),\n",
        "        (\"fine\", kxx)\n",
        "    ]\n",
        "\n",
        "    save = pp.Exporter(spe10.sd, \"upscaled_k\", folder_name=folder_results)\n",
        "    save.write_vtu(var_to_save)\n",
        "\n",
        "    write_upscaled_perm(\"as_tensor\", sd_coarse, result, folder_results)\n",
        "\n",
        "    return sd_coarse, result"
      ],
      "metadata": {
        "id": "7Z92C2rtBl8V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "selected_layers = 20\n",
        "folder_results = main_folder + \"results/\"\n",
        "\n",
        "sd_coarse, result = Checkpoint1_solution(selected_layers, folder_results)"
      ],
      "metadata": {
        "id": "t9HJgjByBnYq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}