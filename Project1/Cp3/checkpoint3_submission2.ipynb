{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyP2v53VnqA68Ar20/0Z4kl7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Alepescinaa/ScientificTools/blob/main/Project1/Cp3/checkpoint3_submission2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy.io\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "#!pip -q install pyDOE\n",
        "from pyDOE import lhs\n",
        "\n",
        "# set seed for reproducibility\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)"
      ],
      "metadata": {
        "id": "7LMzRH1i45zz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "basis = np.loadtxt('U.txt')"
      ],
      "metadata": {
        "id": "Juxq681ro30s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c1_min = -14901.761523641348\n",
        "c2_min = -1643.3531739641028\n",
        "c3_min = -1666.6210868100304\n",
        "c4_min = -776.3216433826997\n",
        "c5_min = -1093.9739152896575\n",
        "c6_min = -717.0421965070655\n",
        "c7_min = -469.99557868963177\n",
        "c8_min = -328.78040407702787\n",
        "c9_min = -257.80546030166914\n",
        "c10_min = -216.04071913734091\n",
        "\n",
        "delta_c1 = 2757.9742726495806\n",
        "delta_c2 = 3222.8072248540147\n",
        "delta_c3 = 3374.1788513410456\n",
        "delta_c4 = 2057.0735047085477\n",
        "delta_c5 = 2141.6130258360363\n",
        "delta_c6 = 1254.632759668237\n",
        "delta_c7 = 908.8248889044971\n",
        "delta_c8 = 857.0009344594488\n",
        "delta_c9 = 575.4097642690142\n",
        "delta_c10 = 573.6208325456312"
      ],
      "metadata": {
        "id": "Ifvvx8Cbr9qD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_points = 151\n",
        "x = np.linspace(-1.5, 1.5, num_points)\n",
        "y = np.linspace(-1.5, 1.5, num_points)\n",
        "X, Y = np.meshgrid(x, y)\n",
        "xcl = tf.expand_dims(X.ravel(), axis=-1)\n",
        "ycl = tf.expand_dims(Y.ravel(), axis=-1)\n",
        "X_coll = tf.concat([xcl, ycl], 1)\n",
        "X_coll"
      ],
      "metadata": {
        "id": "9-akie5L_u3V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def penalty(param, lower_bound, upper_bound):\n",
        "    return tf.reduce_sum(tf.square(tf.maximum(param - upper_bound, 0)) +\n",
        "                         tf.square(tf.maximum(lower_bound - param, 0)))\n",
        "\n",
        "# PINN loss function\n",
        "def loss(xcl,ycl,xmeas,ymeas,umeas,coeff_1,coeff_2,coeff_3,coeff_other):\n",
        "    input_data=tf.concat([xmeas,ymeas],1)\n",
        "    umeas_pred = PINN(input_data)\n",
        "    r_pred   = r_PINN(xcl,ycl,coeff_1,coeff_2,coeff_3,coeff_other)\n",
        "\n",
        "    # loss components\n",
        "    mse_meas  = tf.reduce_mean(tf.pow(umeas-umeas_pred,2))\n",
        "    mse_r  = tf.reduce_mean(tf.abs(r_pred))\n",
        "\n",
        "    # bc\n",
        "    y0 = tf.constant([-0.517409965],dtype=tf.float64)\n",
        "    mse_bc= tf.pow( PINN( tf.transpose( tf.stack( [tf.constant([1.5],dtype=tf.float64), y0] ) ) ) ,2)\n",
        "\n",
        "    #penalty\n",
        "    mse_penalty = penalty(coeff_other[0],0,1)+penalty(coeff_other[1],0,1)+penalty(coeff_other[2],0,1)+penalty(coeff_other[3],0,1)+penalty(coeff_other[4],0,1)+penalty(coeff_other[5],0,1)+penalty(coeff_other[6],0,1)+penalty(coeff_1,0,1)+penalty(coeff_2,0,1)+penalty(coeff_3,0,1)\n",
        "\n",
        "    return mse_meas + mse_r + mse_bc + mse_penalty\n",
        "\n",
        "def loss2(xcl,ycl,xmeas,ymeas,umeas):\n",
        "    input_data=tf.concat([xmeas,ymeas],1)\n",
        "    umeas_pred = PINN(input_data)\n",
        "    r_pred   = r_PINN2(xcl,ycl)\n",
        "\n",
        "    # loss components\n",
        "    mse_meas  = tf.reduce_mean(tf.pow(umeas-umeas_pred,2))\n",
        "    mse_r  = tf.reduce_mean(tf.abs(r_pred))\n",
        "\n",
        "    # bc\n",
        "    y0 = tf.constant([-0.517409965],dtype=tf.float64)\n",
        "    mse_bc= tf.pow( PINN( tf.transpose( tf.stack( [tf.constant([1.5],dtype=tf.float64), y0] ) ) ) ,2)\n",
        "\n",
        "    return mse_meas + mse_r + mse_bc\n",
        "\n",
        "@tf.function\n",
        "def r_PINN(x,y,coeff_1,coeff_2,coeff_3,coeff_other):\n",
        "    input_data=tf.concat([x,y],1)\n",
        "    u = PINN(input_data)\n",
        "    u_x = tf.gradients(u,x)[0]\n",
        "    u_y = tf.gradients(u,y)[0]\n",
        "    u_grad = tf.transpose(tf.concat([u_x, u_y], axis=1))\n",
        "\n",
        "    pi = tf.constant(np.pi,dtype=tf.float64)\n",
        "    theta_fiber = tf.constant([0.13757033666666668] ,dtype=tf.float64)\n",
        "    a_ratio = tf.constant([5.896298503333333], dtype=tf.float64)\n",
        "    theta0 = pi/2 - theta_fiber\n",
        "\n",
        "    a = tf.stack([tf.cos(theta0), tf.sin(theta0)])\n",
        "    b = tf.stack([tf.cos(theta0-pi/2), tf.sin(theta0-pi/2)])\n",
        "\n",
        "    D_00 = 1 / a_ratio * a[0]**2 + b[0]**2\n",
        "    D_01 = 1 / a_ratio * a[0] * a[1] + b[0] * b[1]\n",
        "    D_10 = 1 / a_ratio * a[0] * a[1] + b[0] * b[1]\n",
        "    D_11 = 1 / a_ratio * a[1]**2 + b[1]**2\n",
        "\n",
        "    c1 = c1_min + delta_c1 * coeff_1\n",
        "    c2 = c2_min + delta_c2 * coeff_2\n",
        "    c3 = c3_min + delta_c3 * coeff_3\n",
        "    c4 = c4_min + delta_c4 * coeff_other[0]\n",
        "    c5 = c5_min + delta_c5 * coeff_other[1]\n",
        "    c6 = c6_min + delta_c6 * coeff_other[2]\n",
        "    c7 = c7_min + delta_c7 * coeff_other[3]\n",
        "    c8 = c8_min + delta_c8 * coeff_other[4]\n",
        "    c9 = c9_min + delta_c9 * coeff_other[5]\n",
        "    c10 = c10_min + delta_c10 * coeff_other[6]\n",
        "\n",
        "    coeff_true = tf.expand_dims(tf.concat([c1[0],c2[0],c3[0],c4,c5,c6,c7,c8,c9,c10], 0), 1)\n",
        "\n",
        "    return   (((u_x * D_00 * u_x + u_x * D_01 * u_y + u_y * D_10 * u_x + u_y * D_11 * u_y)))  - (1/(basis@coeff_true))**2\n",
        "\n",
        "@tf.function\n",
        "def r_PINN2(x,y):\n",
        "    input_data=tf.concat([x,y],1)\n",
        "    u = PINN(input_data)\n",
        "    u_x = tf.gradients(u,x)[0]\n",
        "    u_y = tf.gradients(u,y)[0]\n",
        "    u_grad = tf.transpose(tf.concat([u_x, u_y], axis=1))\n",
        "\n",
        "    pi = tf.constant(np.pi,dtype=tf.float64)\n",
        "    theta_fiber = tf.constant([0.13757033666666668] ,dtype=tf.float64)\n",
        "    a_ratio = tf.constant([5.896298503333333], dtype=tf.float64)\n",
        "    theta0 = pi/2 - theta_fiber\n",
        "\n",
        "    a = tf.stack([tf.cos(theta0), tf.sin(theta0)])\n",
        "    b = tf.stack([tf.cos(theta0-pi/2), tf.sin(theta0-pi/2)])\n",
        "\n",
        "    D_00 = 1 / a_ratio * a[0]**2 + b[0]**2\n",
        "    D_01 = 1 / a_ratio * a[0] * a[1] + b[0] * b[1]\n",
        "    D_10 = 1 / a_ratio * a[0] * a[1] + b[0] * b[1]\n",
        "    D_11 = 1 / a_ratio * a[1]**2 + b[1]**2\n",
        "\n",
        "    return  (((u_x * D_00 * u_x + u_x * D_01 * u_y + u_y * D_10 * u_x + u_y * D_11 * u_y)))  - (1/100)**2\n",
        "\n",
        "\n",
        "# neural network weight gradients\n",
        "@tf.function\n",
        "def grad(model,xcl,ycl,xmeas,ymeas,umeas,coeff_1,coeff_2,coeff_3,coeff_other):\n",
        "    with tf.GradientTape(persistent=True) as tape:\n",
        "        loss_value = loss(xcl,ycl,xmeas,ymeas,umeas,coeff_1,coeff_2,coeff_3,coeff_other)\n",
        "        grads = tape.gradient(loss_value,model.trainable_variables)\n",
        "        grads_c1 = tape.gradient(loss_value,coeff_1)\n",
        "        grads_c2 = tape.gradient(loss_value,coeff_2)\n",
        "        grads_c3 = tape.gradient(loss_value,coeff_3)\n",
        "        grads_other = tape.gradient(loss_value,coeff_other)\n",
        "\n",
        "    return loss_value,grads,grads_c1,grads_c2,grads_c3,grads_other\n",
        "    # neural network weight gradients\n",
        "\n",
        "@tf.function\n",
        "def grad2(model,xcl,ycl,xmeas,ymeas,umeas):\n",
        "    with tf.GradientTape(persistent=True) as tape:\n",
        "        loss_value2 = loss2(xcl,ycl,xmeas,ymeas,umeas)\n",
        "        grads2 = tape.gradient(loss_value2,model.trainable_variables)\n",
        "    return loss_value2, grads2"
      ],
      "metadata": {
        "id": "D6GImuip_9iB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.layers import LSTM\n",
        "\n",
        "regularization_strength = 1e-3\n",
        "\n",
        "PINN = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(64, activation='relu', input_shape=(2,),\n",
        "                          kernel_initializer=\"glorot_uniform\",\n",
        "                          kernel_regularizer=regularizers.l2(regularization_strength),\n",
        "                          dtype=tf.float64),\n",
        "\n",
        "    tf.keras.layers.Dense(128, activation='relu',\n",
        "                          kernel_initializer=\"glorot_uniform\",\n",
        "                          kernel_regularizer=regularizers.l2(regularization_strength),\n",
        "                          dtype=tf.float64),\n",
        "\n",
        "    tf.keras.layers.Dense(32, activation='relu',\n",
        "                          kernel_initializer=\"glorot_uniform\",\n",
        "                          kernel_regularizer=regularizers.l2(regularization_strength),\n",
        "                          dtype=tf.float64),\n",
        "\n",
        "    tf.keras.layers.Dense(1, activation=None,\n",
        "                          kernel_initializer=\"glorot_uniform\",\n",
        "                          kernel_regularizer=regularizers.l2(regularization_strength),\n",
        "                          dtype=tf.float64)\n",
        "])"
      ],
      "metadata": {
        "id": "J3LoK5-zAA2T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def checkpoint2_solution( x, y , t ):\n",
        "\n",
        "  x = tf.constant(x.reshape(20, 1), dtype=tf.float64)\n",
        "  y = tf.constant(y.reshape(20, 1), dtype=tf.float64)\n",
        "  t = tf.constant(t.reshape(20, 1), dtype=tf.float64)\n",
        "\n",
        "  coeff_1 = tf.Variable([[0.5]], trainable=True, dtype=tf.float64)\n",
        "  coeff_2 = tf.Variable([[0.5]], trainable=True, dtype=tf.float64)\n",
        "  coeff_3 = tf.Variable([[0.5]], trainable=True, dtype=tf.float64)\n",
        "  coeff_other = tf.Variable([[0.5],[0.5],[0.5],[0.5],[0.5],[0.5],[0.5]], trainable=True, dtype=tf.float64)\n",
        "\n",
        "  tf_optimizer_PINN = tf.keras.optimizers.Adam(learning_rate=0.01,beta_1=0.99)\n",
        "  tf_optimizer_PINN.build(PINN.trainable_variables)\n",
        "  tf_optimizer_c1 = tf.keras.optimizers.Adam(learning_rate=0.01,beta_1=0.99)\n",
        "  tf_optimizer_c1.build([coeff_1])\n",
        "  tf_optimizer_c2 = tf.keras.optimizers.Adam(learning_rate=0.01,beta_1=0.99)\n",
        "  tf_optimizer_c2.build([coeff_2])\n",
        "  tf_optimizer_c3 = tf.keras.optimizers.Adam(learning_rate=0.01,beta_1=0.99)\n",
        "  tf_optimizer_c3.build([coeff_3])\n",
        "  tf_optimizer_other = tf.keras.optimizers.Adam(learning_rate=0.01,beta_1=0.99)\n",
        "  tf_optimizer_other.build([coeff_other])\n",
        "\n",
        "  for iter in range(1500):\n",
        "\n",
        "    loss_value2,grads2 = grad2(PINN,xcl,ycl,x, y, t)\n",
        "\n",
        "    tf_optimizer_PINN.apply_gradients(zip(grads2,PINN.trainable_variables))\n",
        "\n",
        "  for iter in range(4000):\n",
        "\n",
        "    loss_value,grads,grads_c1,grads_c2,grads_c3,grads_other = grad(PINN,xcl,ycl,x, y, t,coeff_1,coeff_2,coeff_3,coeff_other)\n",
        "\n",
        "    tf_optimizer_PINN.apply_gradients(zip(grads ,PINN.trainable_variables))\n",
        "    tf_optimizer_c1.apply_gradients(zip([grads_c1], [coeff_1]))\n",
        "    tf_optimizer_c2.apply_gradients(zip([grads_c2], [coeff_2]))\n",
        "    tf_optimizer_c3.apply_gradients(zip([grads_c3], [coeff_3]))\n",
        "    tf_optimizer_other.apply_gradients(zip([grads_other], [coeff_other]))\n",
        "\n",
        "  c1 = c1_min + delta_c1 * coeff_1\n",
        "  c2 = c2_min + delta_c2 * coeff_2\n",
        "  c3 = c3_min + delta_c3 * coeff_3\n",
        "  c4 = c4_min + delta_c4 * coeff_other[0]\n",
        "  c5 = c5_min + delta_c5 * coeff_other[1]\n",
        "  c6 = c6_min + delta_c6 * coeff_other[2]\n",
        "  c7 = c7_min + delta_c7 * coeff_other[3]\n",
        "  c8 = c8_min + delta_c8 * coeff_other[4]\n",
        "  c9 = c9_min + delta_c9 * coeff_other[5]\n",
        "  c10 = c10_min + delta_c10 * coeff_other[6]\n",
        "\n",
        "  coeff_true = tf.expand_dims(tf.concat([c1[0],c2[0],c3[0],c4,c5,c6,c7,c8,c9,c10], 0), 1)\n",
        "\n",
        "  speed_field_est = basis @ coeff_true\n",
        "\n",
        "  return speed_field_est"
      ],
      "metadata": {
        "id": "JhrY8lnAAG8b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "speed_field_est = checkpoint2_solution(x_meas, y_meas, t_meas)"
      ],
      "metadata": {
        "id": "TRlUfilbAKB_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}