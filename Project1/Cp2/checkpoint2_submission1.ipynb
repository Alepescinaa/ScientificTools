{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMDov+s/4C7EJyctai+uZka",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Alepescinaa/ScientificTools/blob/main/Project1/cp2/checkpoint2_submission1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "uNmk-BAaFciZ"
      },
      "outputs": [],
      "source": [
        "# import required libraries\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import scipy.io\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
        "from sklearn.model_selection import train_test_split\n",
        "!pip -q install pyDOE\n",
        "from pyDOE import lhs  # for latin hypercube sampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "iPZ7AMmXMNSB"
      },
      "outputs": [],
      "source": [
        "# set seed for reproducibility\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# collocation points\n",
        "Ncl = 10000\n",
        "Xcl = lhs(2,Ncl)\n",
        "xcl = tf.expand_dims(tf.cast(-1.5+(3.0)*Xcl[:,0],dtype=tf.float64),axis=-1)\n",
        "ycl = tf.expand_dims(tf.cast(-1.5+(3.0)*Xcl[:,1],dtype=tf.float64),axis=-1)\n",
        "X_coll = tf.concat([xcl,ycl],1)"
      ],
      "metadata": {
        "id": "Io-jdXVYG2fq"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def penalty(param, lower_bound, upper_bound):\n",
        "    return tf.reduce_sum(tf.square(tf.maximum(param - upper_bound, 0)) +\n",
        "                         tf.square(tf.maximum(lower_bound - param, 0)))\n",
        "# Residual loss\n",
        "def r_PINN(x,y,param):\n",
        "    input_data=tf.concat([x,y],1)\n",
        "    u = PINN(input_data)\n",
        "    u_x = tf.gradients(u,x)[0]\n",
        "    u_y = tf.gradients(u,y)[0]\n",
        "    u_grad = tf.transpose(tf.concat([u_x, u_y], axis=1))\n",
        "\n",
        "    theta0 = pi/2 - param[0]\n",
        "    a = tf.stack([tf.cos(theta0), tf.sin(theta0)])\n",
        "    b = tf.stack([tf.cos(theta0-pi/2), tf.sin(theta0-pi/2)])\n",
        "\n",
        "    D_00 = 1 / param[1] * a[0]**2 + b[0]**2\n",
        "    D_01 = 1 / param[1] * a[0] * a[1] + b[0] * b[1]\n",
        "    D_10 = 1 / param[1] * a[0] * a[1] + b[0] * b[1]\n",
        "    D_11 = 1 / param[1] * a[1]**2 + b[1]**2\n",
        "\n",
        "    return tf.sqrt((u_x * D_00 * u_x + u_x * D_01 * u_y + u_y * D_10 * u_x + u_y * D_11 * u_y))  - 1/100\n",
        "\n",
        "# PINN loss function\n",
        "def loss(xcl,ycl,xmeas,ymeas,umeas,param):\n",
        "    input_data=tf.concat([xmeas,ymeas],1)\n",
        "    umeas_pred = PINN(input_data)\n",
        "    r_pred   = r_PINN(xcl,ycl,param)\n",
        "\n",
        "    # loss components\n",
        "    mse_meas  = tf.reduce_mean(tf.pow(umeas-umeas_pred,2))\n",
        "    mse_r  = tf.reduce_mean(tf.pow(r_pred,2))\n",
        "\n",
        "    # bc\n",
        "    mse_bc= tf.pow( PINN( tf.transpose( tf.stack( [tf.constant([1.5],dtype=tf.float64), param[2] ] ) ) ) ,2)\n",
        "\n",
        "    #penalty over param boundaries\n",
        "    mse_penalty = penalty(param[0],-np.pi/10,np.pi/10)+penalty(param[1],1,9)+penalty(param[2],-1.5,1.5)\n",
        "\n",
        "    return mse_meas + mse_r + mse_bc + mse_penalty\n",
        "\n",
        "# neural network weight gradients\n",
        "@tf.function\n",
        "def grad(model,xcl,ycl,xmeas,ymeas,umeas,param):\n",
        "    with tf.GradientTape(persistent=True) as tape:\n",
        "        loss_value = loss(xcl,ycl,xmeas,ymeas,umeas,param)\n",
        "        grads = tape.gradient(loss_value,model.trainable_variables)\n",
        "        grad_param = tape.gradient(loss_value,param)\n",
        "    return loss_value, grads, grad_param"
      ],
      "metadata": {
        "id": "JTqog6-gGQP4"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.layers import LSTM\n",
        "\n",
        "regularization_strength = 1e-3\n",
        "\n",
        "PINN = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(32, activation='relu', input_shape=(2,),\n",
        "                          kernel_initializer=\"glorot_uniform\",\n",
        "                          kernel_regularizer=regularizers.l2(regularization_strength),\n",
        "                          dtype=tf.float64),\n",
        "\n",
        "    tf.keras.layers.Reshape((1, 32)),\n",
        "\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(units=64)),\n",
        "\n",
        "    tf.keras.layers.Dense(128, activation='relu',\n",
        "                          kernel_initializer=\"glorot_uniform\",\n",
        "                          kernel_regularizer=regularizers.l2(regularization_strength),\n",
        "                          dtype=tf.float64),\n",
        "\n",
        "    tf.keras.layers.Dense(64, activation='relu',\n",
        "                          kernel_initializer=\"glorot_uniform\",\n",
        "                          kernel_regularizer=regularizers.l2(regularization_strength),\n",
        "                          dtype=tf.float64),\n",
        "\n",
        "    tf.keras.layers.Dense(1, activation=None,\n",
        "                          kernel_initializer=\"glorot_uniform\",\n",
        "                          kernel_regularizer=regularizers.l2(regularization_strength),\n",
        "                          dtype=tf.float64)\n",
        "])"
      ],
      "metadata": {
        "id": "9mAnhAExG7HO"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.interpolate import RBFInterpolator\n",
        "\n",
        "def checkpoint1_solution(x, y, t, X, Y, s_value=0.05, s_aniso_1=0.5, s_aniso_2=0.5):\n",
        "    coordinates = np.column_stack((x, y))\n",
        "\n",
        "    mesh_coordinates=np.column_stack((X.ravel(), Y.ravel()))\n",
        "\n",
        "    s = [s_value,s_value,s_value,s_value,s_value,s_value,s_value,s_value,s_value,s_value,s_aniso_1, s_value,s_value,s_value,s_value, s_aniso_2,s_value,s_value,s_value,s_value]\n",
        "\n",
        "    rbf = RBFInterpolator(coordinates, t, neighbors=None, smoothing=s, kernel='thin_plate_spline', epsilon=None, degree=1)\n",
        "\n",
        "    time_pred = rbf(mesh_coordinates)\n",
        "    time_pred=time_pred.reshape(1501,1501)\n",
        "\n",
        "    return time_pred"
      ],
      "metadata": {
        "id": "HAr5JYX2HBEY"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def checkpoint2_solution( x, y , t ):\n",
        "\n",
        "    #train/val split\n",
        "    xmeas_train, xmeas_val, ymeas_train, ymeas_val, tmeas_train, tmeas_val = train_test_split(x, y, t, test_size=0.1)\n",
        "    xmeas_train = tf.constant(xmeas_train.reshape(18, 1), dtype=tf.float64)\n",
        "    ymeas_train = tf.constant(ymeas_train.reshape(18, 1), dtype=tf.float64)\n",
        "    tmeas_train = tf.constant(tmeas_train.reshape(18, 1), dtype=tf.float64)\n",
        "    xmeas_val = tf.constant(xmeas_val.reshape(2, 1), dtype=tf.float64)\n",
        "    ymeas_val = tf.constant(ymeas_val.reshape(2, 1), dtype=tf.float64)\n",
        "    tmeas_val = tf.constant(tmeas_val.reshape(2, 1), dtype=tf.float64)\n",
        "\n",
        "    # y0 initial guess\n",
        "    X, Y = np.meshgrid(np.linspace(-1.5,1.5,1501), np.linspace(-1.5,1.5,1501))\n",
        "    time_pred = checkpoint1_solution(xmeas, ymeas, tmeas, X, Y, s_value=0.05, s_aniso_1=0.5, s_aniso_2=0.5)\n",
        "    y0_initial = Y[np.where(time_pred==np.min(time_pred))]\n",
        "\n",
        "    # param initialization\n",
        "    pi = tf.constant(np.pi,dtype=tf.float64)\n",
        "    param = tf.Variable([[0.01], [3], [y0_initial[0]]], trainable=True,dtype=tf.float64)\n",
        "\n",
        "    # Adam optimizer\n",
        "    initial_learning_rate = 0.002\n",
        "    tf_optimizer = tf.keras.optimizers.Adam(learning_rate=initial_learning_rate,beta_1=0.99)\n",
        "\n",
        "    patience = float('inf')\n",
        "    patience_lr = 500\n",
        "    min_delta = 1e-9\n",
        "    best_val_loss = float('inf')\n",
        "    wait = 0\n",
        "    count = 0\n",
        "\n",
        "    for iter in range(12000):\n",
        "\n",
        "      # compute gradients using AD\n",
        "      loss_value,grads,grad_param = grad(PINN,xcl,ycl,xmeas_train, ymeas_train, tmeas_train, param)\n",
        "\n",
        "      # update neural network weights\n",
        "      tf_optimizer.apply_gradients(zip(grads+[grad_param],PINN.trainable_variables+[param]))\n",
        "\n",
        "      loss_value_val, _, _ = grad(PINN, xcl, ycl, xmeas_val, ymeas_val, tmeas_val, param)\n",
        "\n",
        "      best_weigths = None\n",
        "      best_params = None\n",
        "\n",
        "      # Early stopping\n",
        "      if loss_value_val < best_val_loss - min_delta:\n",
        "          best_val_loss = loss_value_val\n",
        "          wait = 0\n",
        "          count = 0\n",
        "          best_weights = PINN.get_weights()\n",
        "          best_params = param.numpy()\n",
        "      else:\n",
        "          wait += 1\n",
        "          count += 1\n",
        "\n",
        "          if count >= patience_lr:\n",
        "            tf_optimizer.learning_rate = tf_optimizer.learning_rate * 0.9\n",
        "            count = 0\n",
        "\n",
        "          if wait >= patience:\n",
        "              print('Early stopping at epoch', iter + 1)\n",
        "              break\n",
        "\n",
        "      # display intermediate results\n",
        "      if ((iter+1) % 100 == 0):\n",
        "        print('iter =  '+str(iter+1))\n",
        "        #loss_value_np=loss_value.numpy()\n",
        "        #print('loss = {:.4f}'.format(loss_value_np))\n",
        "        tf.print('loss =' , loss_value)\n",
        "        tf.print('loss_val_param =' , loss_value_val)\n",
        "\n",
        "        print(param.numpy())\n",
        "\n",
        "    return param[0], param[1], param[2]"
      ],
      "metadata": {
        "id": "AMtbM_TYGxHl"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# measurement points\n",
        "ind_disp = 0\n",
        "xmeas = CP2data[ind_disp][0]\n",
        "ymeas = CP2data[ind_disp][1]\n",
        "tmeas = CP2data[ind_disp][2]\n",
        "theta_fiber, a_ratio, y0 = checkpoint2_solution( xmeas, ymeas , tmeas)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ppTNciWYKLnN",
        "outputId": "c22b9a55-9cdd-4df1-e6c7-b048b9ce6bd5"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iter =  100\n",
            "loss = [[1.7300935140234834e-05]]\n",
            "loss_val_param = [[3.5013219931420777e-05]]\n",
            "[[-0.0202273 ]\n",
            " [ 3.17624334]\n",
            " [ 0.67089952]]\n",
            "iter =  200\n",
            "loss = [[1.3225575025701779e-05]]\n",
            "loss_val_param = [[1.602736172850893e-05]]\n",
            "[[-0.0704666 ]\n",
            " [ 3.35306324]\n",
            " [ 0.72559667]]\n",
            "iter =  300\n",
            "loss = [[1.1629482953081272e-05]]\n",
            "loss_val_param = [[2.6298739468318424e-05]]\n",
            "[[-0.11864594]\n",
            " [ 3.52266358]\n",
            " [ 0.77508938]]\n",
            "iter =  400\n",
            "loss = [[6.6731665447265811e-06]]\n",
            "loss_val_param = [[1.0852189934090679e-05]]\n",
            "[[-0.1480649 ]\n",
            " [ 3.67970783]\n",
            " [ 0.83932603]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "theta_fiber, a_ratio, y0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q0_yBA-xKsbC",
        "outputId": "1ad247dc-03ba-40d8-8225-b0807736caed"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(1,), dtype=float64, numpy=array([-0.1480649])>,\n",
              " <tf.Tensor: shape=(1,), dtype=float64, numpy=array([3.67970783])>,\n",
              " <tf.Tensor: shape=(1,), dtype=float64, numpy=array([0.83932603])>)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    }
  ]
}
