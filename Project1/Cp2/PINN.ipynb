{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Alepescinaa/ScientificTools/blob/main/Project1/Cp2/PINN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9QxtRkHFzOQi"
      },
      "source": [
        "# Exercises: physics-informed neural network\n",
        "\n",
        "Exercise on the implementation of physics-informed neural network.\n",
        "\n",
        "Date: 2024\n",
        "\n",
        "Course: 056936 - SCIENTIFIC COMPUTING TOOLS FOR ADVANCED MATHEMATICAL MODELLING (PAGANI STEFANO) [2023-24].\n",
        "\n",
        "Example adapted from this [notebook](https://colab.research.google.com/drive/1qBrbgevkSBqqYc8bOPiaoJG1MBrBrluN?usp=share_link)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-vC4ZgNMNSA"
      },
      "source": [
        "\n",
        "Let us consider the problem\n",
        "\n",
        "\\begin{aligned}\n",
        "  & v_f *\\sqrt(\\nabla u\\cdot D\\nabla u) =1  \\,, \\quad (x,y) \\in [-1.5,1.5] \\times [-1.5,1.5]\\,\\\\\n",
        "\\end{aligned}\n",
        "\n",
        "where $\\nu$ is unknown. We consider the PINN framework for solving the state/parameter estimation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XJzSWQcWh85s",
        "outputId": "27c155bd-0476-4d08-c518-2011d1f6797c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pyDOE (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "# import required libraries\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import scipy.io\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
        "!pip -q install pyDOE\n",
        "from pyDOE import lhs  # for latin hypercube sampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iPZ7AMmXMNSB"
      },
      "outputs": [],
      "source": [
        "# set seed for reproducibility\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Alepescinaa/ScientificTools\n",
        "%cd ScientificTools/Project1/Cp2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81xKLGYAPWAn",
        "outputId": "65b08ffa-3ddc-4611-87f2-c8a7a59ca2b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ScientificTools'...\n",
            "remote: Enumerating objects: 374, done.\u001b[K\n",
            "remote: Counting objects: 100% (218/218), done.\u001b[K\n",
            "remote: Compressing objects: 100% (202/202), done.\u001b[K\n",
            "remote: Total 374 (delta 64), reused 1 (delta 1), pack-reused 156\u001b[K\n",
            "Receiving objects: 100% (374/374), 99.95 MiB | 11.25 MiB/s, done.\n",
            "Resolving deltas: 100% (102/102), done.\n",
            "/content/ScientificTools/Project1/Cp2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# loading of the dataset\n",
        "\n",
        "CP2data = np.load(\"CP2data.npz\")\n",
        "CP2data = CP2data['arr_0']"
      ],
      "metadata": {
        "id": "DyWUj69OzdAk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loading of the estimate\n",
        "\n",
        "CP2estimate = np.load(\"CP2estimate.npz\")\n",
        "CP2estimate = CP2estimate['arr_0']"
      ],
      "metadata": {
        "id": "uZuKEdpozkw5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CP2estimate[4]"
      ],
      "metadata": {
        "id": "KbhxLMETxrc4",
        "outputId": "ad72e599-7f86-42dd-bd19-61a29d065cc5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.1226488 , 3.6316356 , 0.84714825])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "klhbmUomMNSC"
      },
      "source": [
        "# Solution"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X, Y = np.meshgrid(np.linspace(-1.5,1.5,151), np.linspace(-1.5,1.5,151))\n",
        "X_flat = tf.convert_to_tensor(np.hstack((X.flatten()[:,None],Y.flatten()[:,None])),dtype=tf.float64)\n",
        "x0 = 1.5\n",
        "#activation_time = anysotropic_FMM( x0 , y0 , X, Y, sigma_11,sigma_12, sigma_21, sigma_22 )"
      ],
      "metadata": {
        "id": "sE3cYo19z9-6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wqZ_fC-1KON_"
      },
      "outputs": [],
      "source": [
        "def penalty(param, lower_bound, upper_bound):\n",
        "    return tf.reduce_sum(tf.square(tf.maximum(param - upper_bound, 0)) +\n",
        "                         tf.square(tf.maximum(lower_bound - param, 0)))\n",
        "# PINN loss function\n",
        "def loss(xcl,ycl,xmeas,ymeas,umeas,param):\n",
        "    umeas_pred = PINN(tf.concat([xmeas,ymeas],1))\n",
        "    r_pred   = r_PINN(xcl,ycl,param)\n",
        "\n",
        "    # loss components\n",
        "    mse_meas  = tf.reduce_mean(tf.pow(umeas-umeas_pred,2))\n",
        "    mse_r  = tf.reduce_mean(tf.pow(r_pred,2))\n",
        "\n",
        "    # bc\n",
        "    mse_bc= tf.pow( PINN( tf.transpose( tf.stack( [tf.constant([1.5],dtype=tf.float64), param[2] ] ) ) ) ,2)\n",
        "\n",
        "    #penalty over param boundaries\n",
        "    mse_penalty=penalty(param[0],-np.pi/10,np.pi/10)+penalty(param[1],1,9)+penalty(param[2],-1.5,1.5)\n",
        "\n",
        "    return mse_r + mse_meas + mse_bc + mse_penalty\n",
        "    #tf.print('mse_time',mse_meas)\n",
        "    #tf.print('mse_param',mse_r)\n",
        "    #tf.print('mse_bc',mse_bc)\n",
        "\n",
        "# neural network weight gradients\n",
        "@tf.function\n",
        "def grad(model,xcl,ycl,xmeas,ymeas,umeas,param):\n",
        "    with tf.GradientTape(persistent=True) as tape:\n",
        "        loss_value = loss(xcl,ycl,xmeas,ymeas,umeas,param)\n",
        "        grads = tape.gradient(loss_value,model.trainable_variables)\n",
        "        grad_param = tape.gradient(loss_value,param)\n",
        "    return loss_value, grads, grad_param"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cXUPXsj0KUK0"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# collocation points\n",
        "Ncl = 10000\n",
        "Xcl = lhs(2,Ncl)\n",
        "xcl = tf.expand_dims(tf.cast(-1.5+(3.0)*Xcl[:,0],dtype=tf.float64),axis=-1)\n",
        "ycl = tf.expand_dims(tf.cast(-1.5+(3.0)*Xcl[:,1],dtype=tf.float64),axis=-1)\n",
        "X_coll = tf.concat([xcl,ycl],1)\n",
        "\n",
        "# measurement points\n",
        "ind_disp=4\n",
        "xmeas = CP2data[ind_disp][0]\n",
        "ymeas = CP2data[ind_disp][1]\n",
        "tmeas = CP2data[ind_disp][2]\n",
        "xmeas_train, xmeas_val, ymeas_train, ymeas_val, tmeas_train, tmeas_val = train_test_split(xmeas, ymeas, tmeas, test_size=0.1)\n",
        "xmeas_train = tf.constant(xmeas_train.reshape(18, 1), dtype=tf.float64)\n",
        "ymeas_train = tf.constant(ymeas_train.reshape(18, 1), dtype=tf.float64)\n",
        "tmeas_train = tf.constant(tmeas_train.reshape(18, 1), dtype=tf.float64)\n",
        "xmeas_val = tf.constant(xmeas_val.reshape(2, 1), dtype=tf.float64)\n",
        "ymeas_val = tf.constant(ymeas_val.reshape(2, 1), dtype=tf.float64)\n",
        "tmeas_val = tf.constant(tmeas_val.reshape(2, 1), dtype=tf.float64)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z_cOmQDHKX4k"
      },
      "outputs": [],
      "source": [
        "# training loop\n",
        "\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "regularization_strength =1e-3\n",
        "\n",
        "PINN = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(8, activation='tanh', input_shape=(2,),\n",
        "                          kernel_initializer=\"glorot_normal\",\n",
        "                          kernel_regularizer=regularizers.l2(regularization_strength),\n",
        "                          dtype=tf.float64),\n",
        "    tf.keras.layers.Dense(32, activation='tanh',\n",
        "                          kernel_initializer=\"glorot_normal\",\n",
        "                          kernel_regularizer=regularizers.l2(regularization_strength),\n",
        "                          dtype=tf.float64),\n",
        "    tf.keras.layers.Dense(1, activation=None,\n",
        "                          kernel_initializer=\"glorot_normal\",\n",
        "                          kernel_regularizer=regularizers.l2(regularization_strength),\n",
        "                          dtype=tf.float64)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mNvGaMruMNSD",
        "outputId": "fc437c1d-953f-4682-eaa8-394e069e7d33",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iter =  100\n",
            "loss = [[0.012842736742309874]]\n",
            "loss_val = [[0.014768665156964421]]\n",
            "[[ 0.2165607 ]\n",
            " [ 3.25567154]\n",
            " [-0.03262506]]\n",
            "iter =  200\n",
            "loss = [[0.0016689169917409197]]\n",
            "loss_val = [[0.0018782382685200191]]\n",
            "[[ 0.32069147]\n",
            " [ 3.39161843]\n",
            " [-0.08389283]]\n",
            "iter =  300\n",
            "loss = [[0.0010691755464865243]]\n",
            "loss_val = [[0.0013573127197935755]]\n",
            "[[ 0.28022573]\n",
            " [ 3.46086245]\n",
            " [-0.11955686]]\n",
            "iter =  400\n",
            "loss = [[0.00017359604143097105]]\n",
            "loss_val = [[0.00019134668355448006]]\n",
            "[[ 0.27111998]\n",
            " [ 3.50012027]\n",
            " [-0.13521664]]\n",
            "iter =  500\n",
            "loss = [[0.00027452690259607859]]\n",
            "loss_val = [[0.00023403193333612461]]\n",
            "[[ 0.27051288]\n",
            " [ 3.51865938]\n",
            " [-0.13913044]]\n",
            "iter =  600\n",
            "loss = [[0.00011426445065841282]]\n",
            "loss_val = [[8.44118324352358e-05]]\n",
            "[[ 0.27452319]\n",
            " [ 3.52945907]\n",
            " [-0.13864798]]\n",
            "iter =  700\n",
            "loss = [[0.00011424580056568066]]\n",
            "loss_val = [[8.4440971164441e-05]]\n",
            "[[ 0.27452388]\n",
            " [ 3.52946033]\n",
            " [-0.13864745]]\n",
            "iter =  800\n",
            "loss = [[0.00011424580056568066]]\n",
            "loss_val = [[8.4440971164441e-05]]\n",
            "[[ 0.27452388]\n",
            " [ 3.52946033]\n",
            " [-0.13864745]]\n",
            "iter =  900\n",
            "loss = [[0.00011424580056568066]]\n",
            "loss_val = [[8.4440971164441e-05]]\n",
            "[[ 0.27452388]\n",
            " [ 3.52946033]\n",
            " [-0.13864745]]\n",
            "iter =  1000\n",
            "loss = [[0.00011424580056568066]]\n",
            "loss_val = [[8.4440971164441e-05]]\n",
            "[[ 0.27452388]\n",
            " [ 3.52946033]\n",
            " [-0.13864745]]\n",
            "iter =  1100\n",
            "loss = [[0.00011424580056568066]]\n",
            "loss_val = [[8.4440971164441e-05]]\n",
            "[[ 0.27452388]\n",
            " [ 3.52946033]\n",
            " [-0.13864745]]\n",
            "iter =  1200\n",
            "loss = [[0.00011424580056568066]]\n",
            "loss_val = [[8.4440971164441e-05]]\n",
            "[[ 0.27452388]\n",
            " [ 3.52946033]\n",
            " [-0.13864745]]\n",
            "iter =  1300\n",
            "loss = [[0.00011424580056568066]]\n",
            "loss_val = [[8.4440971164441e-05]]\n",
            "[[ 0.27452388]\n",
            " [ 3.52946033]\n",
            " [-0.13864745]]\n",
            "Early stopping at epoch 1394\n"
          ]
        }
      ],
      "source": [
        "# residual computation based on AD\n",
        "@tf.function\n",
        "def r_PINN(x,y,param):\n",
        "    u = PINN(tf.concat([x,y], 1))\n",
        "    u_x = tf.gradients(u,x)[0]\n",
        "    u_y = tf.gradients(u,y)[0]\n",
        "    u_grad = tf.transpose(tf.concat([u_x, u_y], axis=1))\n",
        "\n",
        "    theta0 = pi/2 - param[0]\n",
        "    a = tf.stack([tf.cos(theta0), tf.sin(theta0)])\n",
        "    b = tf.stack([tf.cos(theta0-pi/2), tf.sin(theta0-pi/2)])\n",
        "\n",
        "    D = ((1/param[1])* tf.linalg.matmul(a,tf.transpose(a)) + tf.linalg.matmul(b,tf.transpose(b)))\n",
        "\n",
        "    #return  tf.linalg.matmul(tf.transpose(u_grad), tf.linalg.matmul(D,u_grad)) - 1/100**2\n",
        "    return tf.sqrt((u_x * D[0,0] * u_x + u_x * D[0,1] * u_y + u_y * D[1,0] * u_x + u_y * D[1,1] * u_y))  - 1/100\n",
        "\n",
        "# Adam optimizer\n",
        "initial_learning_rate=0.005\n",
        "\n",
        "tf_optimizer = tf.keras.optimizers.Adam(learning_rate=initial_learning_rate,beta_1=0.99)\n",
        "\n",
        "# parameter variable try ( 1.45816415][ 3.84494007][-0.95064015]])\n",
        "#param 0 -> fiber anlge (-pi/10,pi/10)\n",
        "#param 1-> aniso (0,1)\n",
        "#param 2-> source y0 (-1.5,1,5)\n",
        "pi = tf.constant(np.pi,dtype=tf.float64)\n",
        "param = tf.Variable([[0.01], [3], [0.1]], trainable=True,dtype=tf.float64)\n",
        "\n",
        "patience = 1000\n",
        "patience_lr= 200\n",
        "min_delta = 1e-9\n",
        "best_val_loss = float('inf')\n",
        "wait = 0\n",
        "\n",
        "for iter in range(20000):\n",
        "\n",
        "  # compute gradients using AD\n",
        "  loss_value,grads,grad_param = grad(PINN,xcl,ycl,xmeas_train, ymeas_train, tmeas_train, param)\n",
        "\n",
        "  # update neural network weights\n",
        "  tf_optimizer.apply_gradients(zip(grads+[grad_param],PINN.trainable_variables+[param]))\n",
        "\n",
        "  val_loss, _, _ = grad(PINN, xcl, ycl, xmeas_val, ymeas_val, tmeas_val, param)\n",
        "\n",
        "\n",
        "\n",
        "  # Early stopping\n",
        "  if val_loss < best_val_loss - min_delta:\n",
        "      best_val_loss = val_loss\n",
        "      wait = 0\n",
        "  else:\n",
        "      wait += 1\n",
        "      if wait >= patience_lr:\n",
        "         tf_optimizer.learning_rate = tf_optimizer.learning_rate/2\n",
        "\n",
        "      if wait >= patience:\n",
        "          print('Early stopping at epoch', iter + 1)\n",
        "          break\n",
        "\n",
        "  # display intermediate results\n",
        "  if ((iter+1) % 100 == 0):\n",
        "    print('iter =  '+str(iter+1))\n",
        "    #loss_value_np=loss_value.numpy()\n",
        "    #print('loss = {:.4f}'.format(loss_value_np ))\n",
        "    tf.print('loss =' , loss_value)\n",
        "    tf.print('loss_val =' , val_loss)\n",
        "\n",
        "    print(param.numpy())\n",
        "    PINN_flat = PINN(X_flat)\n",
        "    \"\"\"\n",
        "    mse = 0.0\n",
        "    time_pred = tf.reshape(PINN_flat, (151, 151))\n",
        "    time_pred = time_pred.numpy()\n",
        "    xmeas=xmeas.numpy().squeeze()\n",
        "    ymeas=ymeas.numpy().squeeze()\n",
        "    tmeas=tmeas.numpy().squeeze()\n",
        "\n",
        "    for k in range(20):\n",
        "            i, j = np.where((X == xmeas[k]) & (Y == ymeas[k]))\n",
        "            mse+= (time_pred[i, j] - tmeas[k]) ** 2\n",
        "\n",
        "    print('mse error: %.4e' % (np.sqrt(mse/20)))\n",
        "\n",
        "    xmeas = tf.constant(xmeas.reshape(20, 1), dtype=tf.float64)\n",
        "    ymeas = tf.constant(ymeas.reshape(20, 1), dtype=tf.float64)\n",
        "    tmeas = tf.constant(tmeas.reshape(20, 1), dtype=tf.float64)\n",
        "    \"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xjbpEPkfWDJe"
      },
      "outputs": [],
      "source": [
        "#Display results\n",
        "\n",
        "N_h = 150\n",
        "X_plot, Y_plot = np.meshgrid(np.linspace(-1.5,1.5,1501), np.linspace(-1.5,1.5,1501))\n",
        "\n",
        "fig = plt.figure(figsize=(16,9),dpi=150)\n",
        "#fig = plt.figure()\n",
        "#fig.subplots_adjust(wspace=0.3)\n",
        "plt.style.use('default')\n",
        "ax = fig.add_subplot(1,3,1)\n",
        "ax.set_aspect(1)\n",
        "im = plt.pcolor(X_plot, Y_plot, u_true)\n",
        "plt.scatter(xmeas,ymeas,marker='x',s=3)\n",
        "divider = make_axes_locatable(ax)\n",
        "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
        "fig.colorbar(im,cax=cax)\n",
        "#ax.set_yticklabels(['-1.0','-0.6','-0.2','0.2','0.6','1.0'])\n",
        "ax.set_title('Exact Solution',fontsize=16)\n",
        "\n",
        "ax = fig.add_subplot(1,3,2)\n",
        "ax.set_aspect(1)\n",
        "im = plt.pcolor(X_plot, Y_plot, np.reshape(PINN_flat,(N_h,N_h)))\n",
        "plt.scatter(xmeas,ymeas,marker='x',s=3)\n",
        "divider = make_axes_locatable(ax)\n",
        "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
        "fig.colorbar(im,cax=cax)\n",
        "ax.set_title('PINN Prediction'.format(err),fontsize=16)\n",
        "\n",
        "ax = fig.add_subplot(1,3,3)\n",
        "ax.set_aspect(1)\n",
        "im = plt.pcolor(X_plot, Y_plot, np.abs( np.reshape(PINN_flat,(N_h,N_h)) -u_true ) )\n",
        "divider = make_axes_locatable(ax)\n",
        "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
        "fig.colorbar(im,cax=cax)\n",
        "ax.set_title('L2 error = {:.4f}'.format(err),fontsize=16)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}