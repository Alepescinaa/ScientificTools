{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Alepescinaa/ScientificTools/blob/main/Project1/Cp2/PINN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9QxtRkHFzOQi"
      },
      "source": [
        "# Exercises: physics-informed neural network\n",
        "\n",
        "Exercise on the implementation of physics-informed neural network.\n",
        "\n",
        "Date: 2024\n",
        "\n",
        "Course: 056936 - SCIENTIFIC COMPUTING TOOLS FOR ADVANCED MATHEMATICAL MODELLING (PAGANI STEFANO) [2023-24].\n",
        "\n",
        "Example adapted from this [notebook](https://colab.research.google.com/drive/1qBrbgevkSBqqYc8bOPiaoJG1MBrBrluN?usp=share_link)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-vC4ZgNMNSA"
      },
      "source": [
        "\n",
        "Let us consider the problem\n",
        "\n",
        "\\begin{aligned}\n",
        "  & v_f *\\sqrt(\\nabla u\\cdot D\\nabla u) =1  \\,, \\quad (x,y) \\in [-1.5,1.5] \\times [-1.5,1.5]\\,\\\\\n",
        "\\end{aligned}\n",
        "\n",
        "where $\\nu$ is unknown. We consider the PINN framework for solving the state/parameter estimation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "XJzSWQcWh85s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe6aa250-034b-4f1c-9294-63f3628abe0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pyDOE (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "# import required libraries\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import scipy.io\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
        "!pip -q install pyDOE\n",
        "from pyDOE import lhs  # for latin hypercube sampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "iPZ7AMmXMNSB"
      },
      "outputs": [],
      "source": [
        "# set seed for reproducibility\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Alepescinaa/ScientificTools\n",
        "%cd ScientificTools/Project1/Cp2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81xKLGYAPWAn",
        "outputId": "94da4d02-117c-455b-8e97-9de0d1ad1133"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ScientificTools'...\n",
            "remote: Enumerating objects: 519, done.\u001b[K\n",
            "remote: Counting objects: 100% (363/363), done.\u001b[K\n",
            "remote: Compressing objects: 100% (279/279), done.\u001b[K\n",
            "remote: Total 519 (delta 120), reused 226 (delta 68), pack-reused 156\u001b[K\n",
            "Receiving objects: 100% (519/519), 129.18 MiB | 13.45 MiB/s, done.\n",
            "Resolving deltas: 100% (158/158), done.\n",
            "/content/ScientificTools/Project1/Cp2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# loading of the dataset\n",
        "\n",
        "CP2data = np.load(\"CP2data.npz\")\n",
        "CP2data = CP2data['arr_0']"
      ],
      "metadata": {
        "id": "DyWUj69OzdAk"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loading of the estimate\n",
        "\n",
        "CP2estimate = np.load(\"CP2estimate.npz\")\n",
        "CP2estimate = CP2estimate['arr_0']"
      ],
      "metadata": {
        "id": "uZuKEdpozkw5"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CP2estimate[3]"
      ],
      "metadata": {
        "id": "KbhxLMETxrc4",
        "outputId": "61ebaa1e-f132-4bd6-a68a-e588eea854c8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.29207564,  5.27909383,  0.9323303 ])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "klhbmUomMNSC"
      },
      "source": [
        "# Solution"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X, Y = np.meshgrid(np.linspace(-1.5,1.5,1501), np.linspace(-1.5,1.5,1501))\n",
        "X_flat = tf.convert_to_tensor(np.hstack((X.flatten()[:,None],Y.flatten()[:,None])),dtype=tf.float64)\n",
        "x0 = 1.5"
      ],
      "metadata": {
        "id": "sE3cYo19z9-6"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "wqZ_fC-1KON_"
      },
      "outputs": [],
      "source": [
        "def penalty(param, lower_bound, upper_bound):\n",
        "    return tf.reduce_sum(tf.square(tf.maximum(param - upper_bound, 0)) +\n",
        "                         tf.square(tf.maximum(lower_bound - param, 0)))\n",
        "# PINN loss function\n",
        "def loss(xcl,ycl,xmeas,ymeas,umeas,theta_fiber,a_ratio,y0):\n",
        "    input_data=tf.concat([xmeas,ymeas],1)\n",
        "    umeas_pred = PINN(input_data)\n",
        "    r_pred   = r_PINN(xcl,ycl,theta_fiber,a_ratio)\n",
        "\n",
        "    # loss components\n",
        "    mse_meas  = tf.reduce_mean(tf.pow(umeas-umeas_pred,2))\n",
        "    mse_r  = tf.reduce_mean(tf.abs(r_pred))\n",
        "\n",
        "    # bc\n",
        "    param_2= -1.5+(1.5+1.5)*y0\n",
        "    mse_bc= tf.pow( PINN( tf.transpose( tf.stack( [tf.constant([1.5],dtype=tf.float64), param_2] ) ) ) ,2)\n",
        "\n",
        "    #penalty over param boundaries\n",
        "    mse_penalty = penalty(theta_fiber,0,1)+penalty(a_ratio,0,1)+penalty(y0,0,1)\n",
        "\n",
        "    #tf.print('mse_time',mse_meas)\n",
        "    #tf.print('mse_param',mse_r)\n",
        "    #tf.print('mse_bc',mse_bc)\n",
        "    return mse_meas + 2*mse_r + 2*mse_bc + mse_penalty\n",
        "\n",
        "\n",
        "# residual computation based on AD\n",
        "@tf.function\n",
        "def r_PINN(x,y,theta_fiber,a_ratio):\n",
        "    input_data=tf.concat([x,y],1)\n",
        "    u = PINN(input_data)\n",
        "    u_x = tf.gradients(u,x)[0]\n",
        "    u_y = tf.gradients(u,y)[0]\n",
        "    u_grad = tf.transpose(tf.concat([u_x, u_y], axis=1))\n",
        "\n",
        "    param_0=-np.pi/10+(np.pi/10+np.pi/10)*theta_fiber\n",
        "    param_1=1+(9-1)*a_ratio\n",
        "    theta0 = pi/2 - param_0\n",
        "    a = tf.stack([tf.cos(theta0), tf.sin(theta0)])\n",
        "    b = tf.stack([tf.cos(theta0-pi/2), tf.sin(theta0-pi/2)])\n",
        "\n",
        "    #D = ((1/param[1])* tf.linalg.matmul(a,tf.transpose(a)) + tf.linalg.matmul(b,tf.transpose(b)))\n",
        "    #return  tf.linalg.matmul(tf.transpose(u_grad), tf.linalg.matmul(D,u_grad)) - 1/100**2\n",
        "    D_00 = 1 / param_1 * a[0]**2 + b[0]**2\n",
        "    D_01 = 1 / param_1 * a[0] * a[1] + b[0] * b[1]\n",
        "    D_10 = 1 / param_1 * a[0] * a[1] + b[0] * b[1]\n",
        "    D_11 = 1 / param_1 * a[1]**2 + b[1]**2\n",
        "\n",
        "    return ((u_x * D_00 * u_x + u_x * D_01 * u_y + u_y * D_10 * u_x + u_y * D_11 * u_y))  - 1/100**2\n",
        "\n",
        "\n",
        "# neural network weight gradients\n",
        "@tf.function\n",
        "def grad(model,xcl,ycl,xmeas,ymeas,umeas,theta_fiber,a_ratio,y0):\n",
        "    with tf.GradientTape(persistent=True) as tape:\n",
        "        loss_value = loss(xcl,ycl,xmeas,ymeas,umeas,theta_fiber,a_ratio,y0)\n",
        "        grads = tape.gradient(loss_value,model.trainable_variables)\n",
        "        grad_tf = tape.gradient(loss_value,theta_fiber)\n",
        "        grad_ar = tape.gradient(loss_value,a_ratio)\n",
        "        grad_y0 = tape.gradient(loss_value,y0)\n",
        "    return loss_value, grads, grad_tf, grad_ar, grad_y0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "cXUPXsj0KUK0"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# collocation points\n",
        "Ncl = 20000\n",
        "Xcl = lhs(2,Ncl)\n",
        "xcl = tf.expand_dims(tf.cast(-1.5+(3.0)*Xcl[:,0],dtype=tf.float64),axis=-1)\n",
        "ycl = tf.expand_dims(tf.cast(-1.5+(3.0)*Xcl[:,1],dtype=tf.float64),axis=-1)\n",
        "X_coll = tf.concat([xcl,ycl],1)\n",
        "\n",
        "# measurement points\n",
        "ind_disp = 2\n",
        "\n",
        "xmeas = CP2data[ind_disp][0]\n",
        "ymeas = CP2data[ind_disp][1]\n",
        "tmeas = CP2data[ind_disp][2]\n",
        "xmeas_train, xmeas_val, ymeas_train, ymeas_val, tmeas_train, tmeas_val = train_test_split(xmeas, ymeas, tmeas, test_size=0.1)\n",
        "xmeas_train = tf.constant(xmeas_train.reshape(18, 1), dtype=tf.float64)\n",
        "ymeas_train = tf.constant(ymeas_train.reshape(18, 1), dtype=tf.float64)\n",
        "tmeas_train = tf.constant(tmeas_train.reshape(18, 1), dtype=tf.float64)\n",
        "xmeas_val = tf.constant(xmeas_val.reshape(2, 1), dtype=tf.float64)\n",
        "ymeas_val = tf.constant(ymeas_val.reshape(2, 1), dtype=tf.float64)\n",
        "tmeas_val = tf.constant(tmeas_val.reshape(2, 1), dtype=tf.float64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "z_cOmQDHKX4k"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.layers import LSTM\n",
        "\n",
        "\n",
        "regularization_strength = 1e-3\n",
        "\n",
        "PINN = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(64, activation='relu', input_shape=(2,),\n",
        "                          kernel_initializer=\"glorot_uniform\",\n",
        "                          kernel_regularizer=regularizers.l2(regularization_strength),\n",
        "                          dtype=tf.float64),\n",
        "     tf.keras.layers.BatchNormalization(),\n",
        "\n",
        "    tf.keras.layers.Reshape((1, 64)),\n",
        "\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(units = 64)),\n",
        "\n",
        "    tf.keras.layers.Dense(128, activation='relu',\n",
        "                          kernel_initializer=\"glorot_uniform\",\n",
        "                          kernel_regularizer=regularizers.l2(regularization_strength),\n",
        "                          dtype=tf.float64),\n",
        "     tf.keras.layers.BatchNormalization(),\n",
        "\n",
        "    tf.keras.layers.Dense(32, activation='relu',\n",
        "                          kernel_initializer=\"glorot_uniform\",\n",
        "                          kernel_regularizer=regularizers.l2(regularization_strength),\n",
        "                          dtype=tf.float64),\n",
        "     tf.keras.layers.BatchNormalization(),\n",
        "\n",
        "    tf.keras.layers.Dense(1, activation=None,\n",
        "                          kernel_initializer=\"glorot_uniform\",\n",
        "                          kernel_regularizer=regularizers.l2(regularization_strength),\n",
        "                          dtype=tf.float64)\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.interpolate import RBFInterpolator\n",
        "\n",
        "def checkpoint1_solution(x, y, t, X, Y, s_value=0.05, s_aniso_1=0.5, s_aniso_2=0.5):\n",
        "    coordinates = np.column_stack((x, y))\n",
        "\n",
        "    mesh_coordinates=np.column_stack((X.ravel(), Y.ravel()))\n",
        "\n",
        "    s = [s_value,s_value,s_value,s_value,s_value,s_value,s_value,s_value,s_value,s_value,s_aniso_1, s_value,s_value,s_value,s_value, s_aniso_2,s_value,s_value,s_value,s_value]\n",
        "\n",
        "    rbf = RBFInterpolator(coordinates, t, neighbors=None, smoothing=s, kernel='thin_plate_spline', epsilon=None, degree=1)\n",
        "\n",
        "    time_pred = rbf(mesh_coordinates)\n",
        "    time_pred=time_pred.reshape(1501,1501)\n",
        "\n",
        "    return time_pred"
      ],
      "metadata": {
        "id": "rtVF3oVFzkQx"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "time_pred=checkpoint1_solution(xmeas, ymeas, tmeas, X, Y, s_value=0.05, s_aniso_1=0.5, s_aniso_2=0.5)"
      ],
      "metadata": {
        "id": "hvLDi9Lg0EPo"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y0_initial=Y[np.where(time_pred==np.min(time_pred))]\n",
        "y0_initial_scaled=(y0_initial+1.5)/3"
      ],
      "metadata": {
        "id": "qEh9jkYcQs57"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "mNvGaMruMNSD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b27eafe3-33ee-4513-e45a-e162f57b9e8e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iter =  100\n",
            "loss = [[0.00034381347124139643]]\n",
            "loss_val_param = [[0.00025464543179726468]]\n",
            "[-0.12117413]\n",
            "[5.]\n",
            "[-1.5]\n",
            "\n",
            "iter =  200\n",
            "loss = [[0.00017240002981948777]]\n",
            "loss_val_param = [[0.00016626977379519391]]\n",
            "[-0.14730783]\n",
            "[5.]\n",
            "[-1.5]\n",
            "\n",
            "iter =  300\n",
            "loss = [[8.2981617129756528e-05]]\n",
            "loss_val_param = [[8.7958907076752388e-05]]\n",
            "[-0.16712577]\n",
            "[5.]\n",
            "[-1.5]\n",
            "\n",
            "iter =  400\n",
            "loss = [[7.7733519184245965e-05]]\n",
            "loss_val_param = [[7.2949878057237768e-05]]\n",
            "[-0.17399296]\n",
            "[5.]\n",
            "[-1.5]\n",
            "\n",
            "iter =  500\n",
            "loss = [[6.3192181758497075e-05]]\n",
            "loss_val_param = [[5.91214185543912e-05]]\n",
            "[-0.17937954]\n",
            "[5.]\n",
            "[-1.5]\n",
            "\n",
            "iter =  600\n",
            "loss = [[4.2913397199684914e-05]]\n",
            "loss_val_param = [[4.0834914056946936e-05]]\n",
            "[-0.18538767]\n",
            "[5.]\n",
            "[-1.5]\n",
            "\n",
            "iter =  700\n",
            "loss = [[3.7695045292758277e-05]]\n",
            "loss_val_param = [[3.900593535117158e-05]]\n",
            "[-0.19508744]\n",
            "[5.]\n",
            "[-1.5]\n",
            "\n",
            "iter =  800\n",
            "loss = [[3.1340963516567084e-05]]\n",
            "loss_val_param = [[3.0051844021092411e-05]]\n",
            "[-0.2039652]\n",
            "[5.]\n",
            "[-1.5]\n",
            "\n",
            "iter =  900\n",
            "loss = [[2.7361511746586406e-05]]\n",
            "loss_val_param = [[2.6036507239275189e-05]]\n",
            "[-0.21634254]\n",
            "[5.]\n",
            "[-1.5]\n",
            "\n",
            "iter =  1000\n",
            "loss = [[2.2010563361393289e-05]]\n",
            "loss_val_param = [[2.033126973334192e-05]]\n",
            "[-0.2173728]\n",
            "[5.]\n",
            "[-1.5]\n",
            "\n",
            "\n",
            "iter =  100\n",
            "loss = [[0.00095709182517751765]]\n",
            "loss_val_param = [[0.0011469372371837624]]\n",
            "[-0.2173728]\n",
            "[7.80515155]\n",
            "[-1.5]\n",
            "\n",
            "iter =  200\n",
            "loss = [[0.00093585341292488542]]\n",
            "loss_val_param = [[0.0010000675334344697]]\n",
            "[-0.2173728]\n",
            "[8.61736132]\n",
            "[-1.5]\n",
            "\n",
            "iter =  300\n",
            "loss = [[0.00094331400202799637]]\n",
            "loss_val_param = [[0.0010705671491909039]]\n",
            "[-0.2173728]\n",
            "[8.94743979]\n",
            "[-1.5]\n",
            "\n",
            "iter =  400\n",
            "loss = [[0.000927292322048845]]\n",
            "loss_val_param = [[0.00099992996050711361]]\n",
            "[-0.2173728]\n",
            "[8.95812535]\n",
            "[-1.5]\n",
            "\n",
            "iter =  500\n",
            "loss = [[0.00092469882575007081]]\n",
            "loss_val_param = [[0.0010020269954346844]]\n",
            "[-0.2173728]\n",
            "[8.92928285]\n",
            "[-1.5]\n",
            "\n",
            "iter =  600\n",
            "loss = [[0.00092386174860731817]]\n",
            "loss_val_param = [[0.0010170860013387541]]\n",
            "[-0.2173728]\n",
            "[8.91736517]\n",
            "[-1.5]\n",
            "\n",
            "iter =  700\n",
            "loss = [[0.00092296946431407682]]\n",
            "loss_val_param = [[0.0010032119585623657]]\n",
            "[-0.2173728]\n",
            "[8.91249979]\n",
            "[-1.5]\n",
            "\n",
            "iter =  800\n",
            "loss = [[0.0009231168821561259]]\n",
            "loss_val_param = [[0.0010109013170998451]]\n",
            "[-0.2173728]\n",
            "[8.9105335]\n",
            "[-1.5]\n",
            "\n",
            "\n",
            "iter =  100\n",
            "loss = [[0.0013944240232887063]]\n",
            "loss_val_param = [[0.0012914040338330504]]\n",
            "[-0.2173728]\n",
            "[8.9105335]\n",
            "[-1.5]\n",
            "\n",
            "iter =  200\n",
            "loss = [[0.0010062970347624281]]\n",
            "loss_val_param = [[0.0011803576100621362]]\n",
            "[-0.2173728]\n",
            "[8.9105335]\n",
            "[-1.5]\n",
            "\n",
            "iter =  300\n",
            "loss = [[0.00095621202128711412]]\n",
            "loss_val_param = [[0.0010651045659100492]]\n",
            "[-0.2173728]\n",
            "[8.9105335]\n",
            "[-1.5]\n",
            "\n",
            "iter =  400\n",
            "loss = [[0.00094024416149405166]]\n",
            "loss_val_param = [[0.00099685383514751561]]\n",
            "[-0.2173728]\n",
            "[8.9105335]\n",
            "[-1.5]\n",
            "\n",
            "iter =  500\n",
            "loss = [[0.00092386564235946147]]\n",
            "loss_val_param = [[0.0010186977943918716]]\n",
            "[-0.2173728]\n",
            "[8.9105335]\n",
            "[-1.5]\n",
            "\n",
            "iter =  600\n",
            "loss = [[0.00092305646274714736]]\n",
            "loss_val_param = [[0.0010023741267841306]]\n",
            "[-0.2173728]\n",
            "[8.9105335]\n",
            "[-1.5]\n",
            "\n",
            "iter =  700\n",
            "loss = [[0.00092362809693207837]]\n",
            "loss_val_param = [[0.0010147499844009571]]\n",
            "[-0.2173728]\n",
            "[8.9105335]\n",
            "[-1.5]\n",
            "\n",
            "iter =  800\n",
            "loss = [[0.00092306271288824062]]\n",
            "loss_val_param = [[0.0010043565230929725]]\n",
            "[-0.2173728]\n",
            "[8.9105335]\n",
            "[-1.5]\n",
            "\n",
            "\n",
            "iter =  100\n",
            "loss = [[0.00092281015710582426]]\n",
            "loss_val_param = [[0.0010061042693612881]]\n",
            "[-0.21685246]\n",
            "[8.91029703]\n",
            "[-1.5]\n",
            "\n",
            "iter =  200\n",
            "loss = [[0.000922811302885062]]\n",
            "loss_val_param = [[0.0010074177426337072]]\n",
            "[-0.21664711]\n",
            "[8.91020285]\n",
            "[-1.5]\n",
            "\n",
            "iter =  300\n",
            "loss = [[0.0009228075553656842]]\n",
            "loss_val_param = [[0.0010073443265966367]]\n",
            "[-0.21656634]\n",
            "[8.91016553]\n",
            "[-1.5]\n",
            "\n",
            "iter =  400\n",
            "loss = [[0.00092280266999852445]]\n",
            "loss_val_param = [[0.0010069571005698608]]\n",
            "[-0.21653467]\n",
            "[8.91015081]\n",
            "[-1.5]\n",
            "\n",
            "iter =  500\n",
            "loss = [[0.000922804011420376]]\n",
            "loss_val_param = [[0.0010067153367646282]]\n",
            "[-0.21652228]\n",
            "[8.91014502]\n",
            "[-1.5]\n",
            "\n",
            "iter =  600\n",
            "loss = [[0.00092280259075528]]\n",
            "loss_val_param = [[0.0010070098857809084]]\n",
            "[-0.21651745]\n",
            "[8.91014275]\n",
            "[-1.5]\n",
            "\n",
            "iter =  700\n",
            "loss = [[0.00092280266090377606]]\n",
            "loss_val_param = [[0.0010070228595014056]]\n",
            "[-0.21651556]\n",
            "[8.91014187]\n",
            "[-1.5]\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-70-88fd986bfbd9>\u001b[0m in \u001b[0;36m<cell line: 139>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m   \u001b[0mloss_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgrad_tf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_ar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_y0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPINN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mxcl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mycl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mxmeas_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mymeas_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtmeas_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta_fiber\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ma_ratio\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m   \u001b[0;31m#tf_optimizer.apply_gradients(zip(grads+[grad_tf, grad_ar, grad_y0],PINN.trainable_variables+[theta_fiber,a_ratio,y0]))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 832\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 877\u001b[0;31m       results = tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    878\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1321\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1322\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1485\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1486\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1487\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1488\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "#param 0 -> fiber angle (-pi/10,pi/10)\n",
        "#param 1-> aniso (0,1)\n",
        "#param 2-> source y0 (-1.5,1,5)\n",
        "\n",
        "pi = tf.constant(np.pi,dtype=tf.float64)\n",
        "theta_fiber = tf.Variable([0.5], trainable=True,dtype=tf.float64)\n",
        "a_ratio = tf.Variable([0.5], trainable=True,dtype=tf.float64)\n",
        "y0 = tf.Variable([y0_initial_scaled[0]], trainable=True,dtype=tf.float64)\n",
        "\n",
        "\n",
        "param0_optimizer = tf.keras.optimizers.Adam(learning_rate=0.01,beta_1=0.99)\n",
        "param0_optimizer.build(PINN.trainable_variables + [theta_fiber])\n",
        "\n",
        "param1_optimizer = tf.keras.optimizers.Adam(learning_rate=0.01,beta_1=0.99)\n",
        "param1_optimizer.build(PINN.trainable_variables + [a_ratio])\n",
        "\n",
        "param2_optimizer = tf.keras.optimizers.Adam(learning_rate=0.008,beta_1=0.99)\n",
        "param2_optimizer.build(PINN.trainable_variables + [y0])\n",
        "\n",
        "\"\"\"\n",
        "initial_learning_rate = 0.01\n",
        "tf_optimizer = tf.keras.optimizers.Adam(learning_rate=initial_learning_rate,beta_1=0.99)\n",
        "tf_optimizer.build(PINN.trainable_variables + [theta_fiber,a_ratio,y0])\n",
        "\n",
        "\n",
        "for iter in range(800):\n",
        "\n",
        "\n",
        "  loss_value,grads,grad_tf, grad_ar, grad_y0 = grad(PINN,xcl,ycl,xmeas_train, ymeas_train, tmeas_train, theta_fiber,a_ratio,y0)\n",
        "\n",
        "  param0_optimizer.apply_gradients(zip(grads,PINN.trainable_variables))\n",
        "\n",
        "  loss_value_val, _, _,_,_ = grad(PINN, xcl, ycl, xmeas_val, ymeas_val, tmeas_val,theta_fiber,a_ratio,y0)\n",
        "\n",
        "  if ((iter+1) % 100 == 0):\n",
        "    print('iter =  '+str(iter+1))\n",
        "    #loss_value_np=loss_value.numpy()\n",
        "    #print('loss = {:.4f}'.format(loss_value_np ))\n",
        "    tf.print('loss =' , loss_value)\n",
        "    tf.print('loss_val_param =' , loss_value_val)\n",
        "\n",
        "    theta_fiber_res= -np.pi/10+np.pi/5*theta_fiber\n",
        "    a_ratio_res=1+8*a_ratio\n",
        "    y0_res=-1.5+3*y0\n",
        "    print(theta_fiber_res.numpy())\n",
        "    print(a_ratio_res.numpy())\n",
        "    print(y0_res.numpy())\n",
        "\"\"\"\n",
        "\n",
        "for iter in range(1000):\n",
        "\n",
        "\n",
        "  loss_value,grads,grad_tf, grad_ar, grad_y0 = grad(PINN,xcl,ycl,xmeas_train, ymeas_train, tmeas_train, theta_fiber,a_ratio,y0)\n",
        "\n",
        "  param0_optimizer.apply_gradients(zip(grads+[grad_tf],PINN.trainable_variables+[theta_fiber]))\n",
        "\n",
        "  loss_value_val, _, _, _, _ = grad(PINN, xcl, ycl, xmeas_val, ymeas_val, tmeas_val,theta_fiber,a_ratio,y0)\n",
        "\n",
        "\n",
        "  if ((iter+1) % 100 == 0):\n",
        "    print('iter =  '+str(iter+1))\n",
        "    #loss_value_np=loss_value.numpy()\n",
        "    #print('loss = {:.4f}'.format(loss_value_np ))\n",
        "    tf.print('loss =' , loss_value)\n",
        "    tf.print('loss_val_param =' , loss_value_val)\n",
        "\n",
        "    theta_fiber_res= -np.pi/10+np.pi/5*theta_fiber\n",
        "    a_ratio_res=1+8*a_ratio\n",
        "    y0_res=-1.5+3*y0\n",
        "    print(theta_fiber_res.numpy())\n",
        "    print(a_ratio_res.numpy())\n",
        "    print(y0_res.numpy())\n",
        "    print()\n",
        "\n",
        "print()\n",
        "for iter in range(800):\n",
        "\n",
        "\n",
        "  loss_value,grads,grad_tf, grad_ar, grad_y0 = grad(PINN,xcl,ycl,xmeas_train, ymeas_train, tmeas_train, theta_fiber,a_ratio,y0)\n",
        "\n",
        "  param1_optimizer.apply_gradients(zip(grads+[grad_ar],PINN.trainable_variables+[a_ratio]))\n",
        "\n",
        "  loss_value_val, _, _, _, _ = grad(PINN, xcl, ycl, xmeas_val, ymeas_val, tmeas_val,theta_fiber,a_ratio,y0)\n",
        "\n",
        "\n",
        "  if ((iter+1) % 100 == 0):\n",
        "    print('iter =  '+str(iter+1))\n",
        "    tf.print('loss =' , loss_value)\n",
        "    tf.print('loss_val_param =' , loss_value_val)\n",
        "\n",
        "    theta_fiber_res= -np.pi/10+np.pi/5*theta_fiber\n",
        "    a_ratio_res=1+8*a_ratio\n",
        "    y0_res=-1.5+3*y0\n",
        "    print(theta_fiber_res.numpy())\n",
        "    print(a_ratio_res.numpy())\n",
        "    print(y0_res.numpy())\n",
        "    print()\n",
        "\n",
        "print()\n",
        "for iter in range(800):\n",
        "\n",
        "\n",
        "  loss_value,grads,grad_tf, grad_ar, grad_y0 = grad(PINN,xcl,ycl,xmeas_train, ymeas_train, tmeas_train, theta_fiber,a_ratio,y0)\n",
        "\n",
        "  param2_optimizer.apply_gradients(zip(grads+[grad_y0],PINN.trainable_variables+[y0]))\n",
        "\n",
        "  loss_value_val, _, _, _, _ = grad(PINN, xcl, ycl, xmeas_val, ymeas_val, tmeas_val,theta_fiber,a_ratio,y0)\n",
        "\n",
        "\n",
        "  if ((iter+1) % 100 == 0):\n",
        "    print('iter =  '+str(iter+1))\n",
        "    #loss_value_np=loss_value.numpy()\n",
        "    #print('loss = {:.4f}'.format(loss_value_np ))\n",
        "    tf.print('loss =' , loss_value)\n",
        "    tf.print('loss_val_param =' , loss_value_val)\n",
        "\n",
        "    theta_fiber_res= -np.pi/10+np.pi/5*theta_fiber\n",
        "    a_ratio_res=1+8*a_ratio\n",
        "    y0_res=-1.5+3*y0\n",
        "    print(theta_fiber_res.numpy())\n",
        "    print(a_ratio_res.numpy())\n",
        "    print(y0_res.numpy())\n",
        "    print()\n",
        "\n",
        "patience = float('inf')\n",
        "patience_lr= float('inf')\n",
        "min_delta = 1e-9\n",
        "best_val_loss = float('inf')\n",
        "wait = 0\n",
        "count = 0\n",
        "\n",
        "\n",
        "param0_optimizer.learning_rate=0.003\n",
        "param1_optimizer.learning_rate=0.003\n",
        "param2_optimizer.learning_rate=0.003\n",
        "\n",
        "#tf_optimizer.learning_rate=0.003\n",
        "print()\n",
        "for iter in range(5000):\n",
        "\n",
        "\n",
        "  loss_value,grads,grad_tf, grad_ar, grad_y0 = grad(PINN,xcl,ycl,xmeas_train, ymeas_train, tmeas_train, theta_fiber,a_ratio,y0)\n",
        "\n",
        "  #tf_optimizer.apply_gradients(zip(grads+[grad_tf, grad_ar, grad_y0],PINN.trainable_variables+[theta_fiber,a_ratio,y0]))\n",
        "\n",
        "  param0_optimizer.apply_gradients(zip(grads+[grad_tf],PINN.trainable_variables+[theta_fiber]))\n",
        "  param1_optimizer.apply_gradients(zip(grads+[grad_ar],PINN.trainable_variables+[a_ratio]))\n",
        "  param2_optimizer.apply_gradients(zip(grads+[grad_y0],PINN.trainable_variables+[y0]))\n",
        "\n",
        "\n",
        "  loss_value_val, _, _,_,_ = grad(PINN, xcl, ycl, xmeas_val, ymeas_val, tmeas_val,theta_fiber,a_ratio,y0)\n",
        "\n",
        "\n",
        "  best_weigths = None\n",
        "  best_params = None\n",
        "\n",
        "  # Early stopping\n",
        "  if loss_value_val < best_val_loss - min_delta:\n",
        "      best_val_loss = loss_value_val\n",
        "      wait = 0\n",
        "      count = 0\n",
        "      best_weights = PINN.get_weights()\n",
        "      best_params = theta_fiber.numpy()\n",
        "  else:\n",
        "      wait += 1\n",
        "      count += 1\n",
        "\n",
        "      if count >= patience_lr:\n",
        "         tf_optimizer.learning_rate = tf_optimizer.learning_rate * 0.9\n",
        "         count = 0\n",
        "\n",
        "      if wait >= patience:\n",
        "          print('Early stopping at epoch', iter + 1)\n",
        "          break\n",
        "\n",
        "\n",
        "  if ((iter+1) % 100 == 0):\n",
        "    print('iter =  '+str(iter+1))\n",
        "    #loss_value_np=loss_value.numpy()\n",
        "    #print('loss = {:.4f}'.format(loss_value_np ))\n",
        "    tf.print('loss =' , loss_value)\n",
        "    tf.print('loss_val_param =' , loss_value_val)\n",
        "\n",
        "    theta_fiber_res= -np.pi/10+np.pi/5*theta_fiber\n",
        "    a_ratio_res=1+8*a_ratio\n",
        "    y0_res=-1.5+3*y0\n",
        "    print(theta_fiber_res.numpy())\n",
        "    print(a_ratio_res.numpy())\n",
        "    print(y0_res.numpy())\n",
        "    print()\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "    PINN_flat = PINN(X_flat)\n",
        "    mse = 0.0\n",
        "    time_pred = tf.reshape(PINN_flat, (151, 151))\n",
        "    time_pred = time_pred.numpy()\n",
        "    xmeas=xmeas.numpy().squeeze()\n",
        "    ymeas=ymeas.numpy().squeeze()\n",
        "    tmeas=tmeas.numpy().squeeze()\n",
        "\n",
        "    for k in range(20):\n",
        "            i, j = np.where((X == xmeas[k]) & (Y == ymeas[k]))\n",
        "            mse+= (time_pred[i, j] - tmeas[k]) ** 2\n",
        "\n",
        "    print('mse error: %.4e' % (np.sqrt(mse/20)))\n",
        "\n",
        "    xmeas = tf.constant(xmeas.reshape(20, 1), dtype=tf.float64)\n",
        "    ymeas = tf.constant(ymeas.reshape(20, 1), dtype=tf.float64)\n",
        "    tmeas = tf.constant(tmeas.reshape(20, 1), dtype=tf.float64)\n",
        "    \"\"\"\n",
        "  #PINN.set_weights(best_weights)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CP2estimate[2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PiSCTkeizbVY",
        "outputId": "9db6f602-6d30-4382-94cf-e903e906c6d2"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.25291165,  4.68768325, -1.22127016])"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "m=20\n",
        "A = np.hstack(   ( np.reshape(xmeas, (m, 1)) , np.reshape(ymeas, (m, 1)) ) )\n",
        "A = np.hstack(   ( A, np.ones((m, 1)) ))\n",
        "b = np.reshape(tmeas, (m, 1))\n",
        "theta = np.dot(np.dot( np.linalg.pinv(np.dot(A.transpose(), A)), A.transpose()), b)\n",
        "#alpha = np.arccos(-1/np.sqrt(theta[0]**2+theta[1]**2+1))\n",
        "( np.arcsin(theta[1]))\n",
        "#alpha =np.rad2deg( np.arctan(theta[1]/theta[0]) )\n",
        "#print(\"angle = %.2f\\n\" % (alpha[0]))\n"
      ],
      "metadata": {
        "id": "JsB7Afs2nV4X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mse=0.0\n",
        "PINN_flat = PINN(X_flat)\n",
        "time_pred_net = tf.reshape(PINN_flat, (151, 151))\n",
        "\n",
        "for i in range(151):\n",
        "  for j in range(151):\n",
        "    mse += (time_pred[i, j] - time_pred_net[i,j]) ** 2\n",
        "\n",
        "mse_sq= np.sqrt(mse/22801)\n",
        "\n",
        "print(np.mean(mse_sq))"
      ],
      "metadata": {
        "id": "YZXmwd7v0SKH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure()\n",
        "fig, ax = plt.subplots(subplot_kw={\"projection\": \"3d\"})\n",
        "surf = ax.plot_surface(X,Y,time_pred, cmap = 'viridis')\n",
        "ax.axes.set_zlim3d(bottom=0, top=np.max(time_pred))\n",
        "fig.colorbar(surf, ax=ax, shrink=0.5, aspect=5)"
      ],
      "metadata": {
        "id": "kQz3ALB04FqS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure()\n",
        "fig, ax = plt.subplots(subplot_kw={\"projection\": \"3d\"})\n",
        "surf = ax.plot_surface(X,Y,time_pred_net, cmap = 'viridis')\n",
        "ax.axes.set_zlim3d(bottom=0, top=np.max(time_pred))\n",
        "fig.colorbar(surf, ax=ax, shrink=0.5, aspect=5)"
      ],
      "metadata": {
        "id": "MuY9AHmX4OXO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.where(time_pred_net==np.min(time_pred_net))"
      ],
      "metadata": {
        "id": "d6Oexo0Q4rsm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y[118,]"
      ],
      "metadata": {
        "id": "jeIdw1Pl45YR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xjbpEPkfWDJe"
      },
      "outputs": [],
      "source": [
        "#Display results\n",
        "\n",
        "N_h = 150\n",
        "X_plot, Y_plot = np.meshgrid(np.linspace(-1.5,1.5,1501), np.linspace(-1.5,1.5,1501))\n",
        "\n",
        "fig = plt.figure(figsize=(16,9),dpi=150)\n",
        "#fig = plt.figure()\n",
        "#fig.subplots_adjust(wspace=0.3)\n",
        "plt.style.use('default')\n",
        "ax = fig.add_subplot(1,3,1)\n",
        "ax.set_aspect(1)\n",
        "im = plt.pcolor(X_plot, Y_plot, u_true)\n",
        "plt.scatter(xmeas,ymeas,marker='x',s=3)\n",
        "divider = make_axes_locatable(ax)\n",
        "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
        "fig.colorbar(im,cax=cax)\n",
        "#ax.set_yticklabels(['-1.0','-0.6','-0.2','0.2','0.6','1.0'])\n",
        "ax.set_title('Exact Solution',fontsize=16)\n",
        "\n",
        "ax = fig.add_subplot(1,3,2)\n",
        "ax.set_aspect(1)\n",
        "im = plt.pcolor(X_plot, Y_plot, np.reshape(PINN_flat,(N_h,N_h)))\n",
        "plt.scatter(xmeas,ymeas,marker='x',s=3)\n",
        "divider = make_axes_locatable(ax)\n",
        "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
        "fig.colorbar(im,cax=cax)\n",
        "ax.set_title('PINN Prediction'.format(err),fontsize=16)\n",
        "\n",
        "ax = fig.add_subplot(1,3,3)\n",
        "ax.set_aspect(1)\n",
        "im = plt.pcolor(X_plot, Y_plot, np.abs( np.reshape(PINN_flat,(N_h,N_h)) -u_true ) )\n",
        "divider = make_axes_locatable(ax)\n",
        "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
        "fig.colorbar(im,cax=cax)\n",
        "ax.set_title('L2 error = {:.4f}'.format(err),fontsize=16)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}