{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Alepescinaa/ScientificTools/blob/main/Project1/Cp2/PINN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9QxtRkHFzOQi"
      },
      "source": [
        "# Exercises: physics-informed neural network\n",
        "\n",
        "Exercise on the implementation of physics-informed neural network.\n",
        "\n",
        "Date: 2024\n",
        "\n",
        "Course: 056936 - SCIENTIFIC COMPUTING TOOLS FOR ADVANCED MATHEMATICAL MODELLING (PAGANI STEFANO) [2023-24].\n",
        "\n",
        "Example adapted from this [notebook](https://colab.research.google.com/drive/1qBrbgevkSBqqYc8bOPiaoJG1MBrBrluN?usp=share_link)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-vC4ZgNMNSA"
      },
      "source": [
        "\n",
        "Let us consider the problem\n",
        "\n",
        "\\begin{aligned}\n",
        "  & v_f *\\sqrt(\\nabla u\\cdot D\\nabla u) =1  \\,, \\quad (x,y) \\in [-1.5,1.5] \\times [-1.5,1.5]\\,\\\\\n",
        "\\end{aligned}\n",
        "\n",
        "where $\\nu$ is unknown. We consider the PINN framework for solving the state/parameter estimation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "XJzSWQcWh85s",
        "outputId": "e4398d75-a4d3-40a7-e34b-ed25300e2dbe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pyDOE (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "# import required libraries\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import scipy.io\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
        "!pip -q install pyDOE\n",
        "from pyDOE import lhs  # for latin hypercube sampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "iPZ7AMmXMNSB"
      },
      "outputs": [],
      "source": [
        "# set seed for reproducibility\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Alepescinaa/ScientificTools\n",
        "%cd ScientificTools/Project1/Cp2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81xKLGYAPWAn",
        "outputId": "49b96d3e-02a6-4b2b-d92a-8f4724d317e6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ScientificTools'...\n",
            "remote: Enumerating objects: 364, done.\u001b[K\n",
            "remote: Counting objects: 100% (208/208), done.\u001b[K\n",
            "remote: Compressing objects: 100% (192/192), done.\u001b[K\n",
            "remote: Total 364 (delta 60), reused 1 (delta 1), pack-reused 156\u001b[K\n",
            "Receiving objects: 100% (364/364), 99.94 MiB | 11.29 MiB/s, done.\n",
            "Resolving deltas: 100% (98/98), done.\n",
            "/content/ScientificTools/Project1/Cp2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# loading of the dataset\n",
        "\n",
        "CP2data = np.load(\"CP2data.npz\")\n",
        "CP2data = CP2data['arr_0']"
      ],
      "metadata": {
        "id": "DyWUj69OzdAk"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loading of the estimate\n",
        "\n",
        "CP2estimate = np.load(\"CP2estimate.npz\")\n",
        "CP2estimate = CP2estimate['arr_0']"
      ],
      "metadata": {
        "id": "uZuKEdpozkw5"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CP2estimate[4]"
      ],
      "metadata": {
        "id": "KbhxLMETxrc4",
        "outputId": "8a58eb92-721f-448f-f747-ba60ce25d6c0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.1226488 , 3.6316356 , 0.84714825])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "klhbmUomMNSC"
      },
      "source": [
        "# Solution"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X, Y = np.meshgrid(np.linspace(-1.5,1.5,1501), np.linspace(-1.5,1.5,1501))\n",
        "X_flat = tf.convert_to_tensor(np.hstack((X.flatten()[:,None],Y.flatten()[:,None])),dtype=tf.float64)\n",
        "x0 = 1.5\n",
        "#activation_time = anysotropic_FMM( x0 , y0 , X, Y, sigma_11,sigma_12, sigma_21, sigma_22 )"
      ],
      "metadata": {
        "id": "sE3cYo19z9-6"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "wqZ_fC-1KON_"
      },
      "outputs": [],
      "source": [
        "# PINN loss function\n",
        "def loss(xcl,ycl,xmeas,ymeas,umeas,param):\n",
        "    umeas_pred = PINN(tf.concat([xmeas,ymeas],1))\n",
        "    r_pred   = r_PINN(xcl,ycl,param)\n",
        "\n",
        "    # loss components\n",
        "    mse_meas  = tf.reduce_mean(tf.pow(umeas-umeas_pred,2))\n",
        "    mse_r  = tf.reduce_mean(tf.pow(r_pred,2))\n",
        "\n",
        "    # bc\n",
        "    mse_bc= tf.pow( PINN( tf.transpose( tf.stack( [tf.constant([1.5],dtype=tf.float64), param[2] ] ) ) ) ,2)\n",
        "\n",
        "    return mse_r + mse_meas + mse_bc\n",
        "\n",
        "# neural network weight gradients\n",
        "@tf.function\n",
        "def grad(model,xcl,ycl,xmeas,ymeas,umeas,param):\n",
        "    with tf.GradientTape(persistent=True) as tape:\n",
        "        loss_value = loss(xcl,ycl,xmeas,ymeas,umeas,param)\n",
        "        grads = tape.gradient(loss_value,model.trainable_variables)\n",
        "        grad_param = tape.gradient(loss_value,param)\n",
        "    return loss_value, grads, grad_param"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "cXUPXsj0KUK0"
      },
      "outputs": [],
      "source": [
        "# collocation points\n",
        "Ncl = 5000\n",
        "Xcl = lhs(2,Ncl)\n",
        "xcl = tf.expand_dims(tf.cast(-1.5+(3.0)*Xcl[:,0],dtype=tf.float64),axis=-1)\n",
        "ycl = tf.expand_dims(tf.cast(-1.5+(3.0)*Xcl[:,1],dtype=tf.float64),axis=-1)\n",
        "X_coll = tf.concat([xcl,ycl],1)\n",
        "\n",
        "# measurement points\n",
        "ind_disp=4\n",
        "xmeas = CP2data[ind_disp][0]\n",
        "ymeas = CP2data[ind_disp][1]\n",
        "tmeas = CP2data[ind_disp][2]\n",
        "xmeas = tf.constant(xmeas.reshape(20, 1), dtype=tf.float64)\n",
        "ymeas = tf.constant(ymeas.reshape(20, 1), dtype=tf.float64)\n",
        "tmeas = tf.constant(tmeas.reshape(20, 1), dtype=tf.float64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "z_cOmQDHKX4k"
      },
      "outputs": [],
      "source": [
        "# training loop\n",
        "\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "regularization_strength = 0.01\n",
        "\n",
        "PINN = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(8, activation='tanh', input_shape=(2,),\n",
        "                          kernel_initializer=\"glorot_normal\",\n",
        "                          kernel_regularizer=regularizers.l2(regularization_strength),\n",
        "                          dtype=tf.float64),\n",
        "    tf.keras.layers.Dense(32, activation='tanh',\n",
        "                          kernel_initializer=\"glorot_normal\",\n",
        "                          kernel_regularizer=regularizers.l2(regularization_strength),\n",
        "                          dtype=tf.float64),\n",
        "    tf.keras.layers.Dense(1, activation=None,\n",
        "                          kernel_initializer=\"glorot_normal\",\n",
        "                          kernel_regularizer=regularizers.l2(regularization_strength),\n",
        "                          dtype=tf.float64)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "mNvGaMruMNSD",
        "outputId": "829043e9-de4a-4de6-a660-a9c75ca96088",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iter =  200\n",
            "loss = [[0.0055370738377029747]]\n",
            "[[-0.05540283]\n",
            " [ 3.40005342]\n",
            " [ 1.31387592]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-15-4ed302246a48>:54: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  print('mse error: %.4e' % (np.sqrt(mse/20)))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mse error: 3.3009e-02\n",
            "iter =  400\n",
            "loss = [[0.00041962664157325208]]\n",
            "[[-0.10578618]\n",
            " [ 3.52363156]\n",
            " [ 1.26460705]]\n",
            "mse error: 1.8219e-02\n",
            "iter =  600\n",
            "loss = [[0.00013580343066028588]]\n",
            "[[-0.11486959]\n",
            " [ 3.54608523]\n",
            " [ 1.25921787]]\n",
            "mse error: 6.8480e-03\n",
            "iter =  800\n",
            "loss = [[2.251799970975174e-05]]\n",
            "[[-0.11639698]\n",
            " [ 3.54986305]\n",
            " [ 1.25791093]]\n",
            "mse error: 4.7506e-03\n",
            "iter =  1000\n",
            "loss = [[1.8662848439813362e-05]]\n",
            "[[-0.11663798]\n",
            " [ 3.55043613]\n",
            " [ 1.25771448]]\n",
            "mse error: 4.3183e-03\n",
            "iter =  1200\n",
            "loss = [[1.4355635469426409e-05]]\n",
            "[[-0.1166683 ]\n",
            " [ 3.55048681]\n",
            " [ 1.25768985]]\n",
            "mse error: 3.7507e-03\n",
            "iter =  1400\n",
            "loss = [[1.1249861734246271e-05]]\n",
            "[[-0.1166637 ]\n",
            " [ 3.55045515]\n",
            " [ 1.25771053]]\n",
            "mse error: 3.3438e-03\n",
            "iter =  1600\n",
            "loss = [[8.90951790600341e-06]]\n",
            "[[-0.11665313]\n",
            " [ 3.55041356]\n",
            " [ 1.2577817 ]]\n",
            "mse error: 2.9822e-03\n",
            "iter =  1800\n",
            "loss = [[7.05869746807947e-06]]\n",
            "[[-0.11664177]\n",
            " [ 3.5503753 ]\n",
            " [ 1.25792516]]\n",
            "mse error: 2.6532e-03\n",
            "iter =  2000\n",
            "loss = [[5.6047915949742733e-06]]\n",
            "[[-0.1166303 ]\n",
            " [ 3.55034424]\n",
            " [ 1.2581627 ]]\n",
            "mse error: 2.3631e-03\n",
            "iter =  2200\n",
            "loss = [[4.4957534325968565e-06]]\n",
            "[[-0.11661801]\n",
            " [ 3.55032269]\n",
            " [ 1.2585133 ]]\n",
            "mse error: 2.1141e-03\n",
            "iter =  2400\n",
            "loss = [[3.6756367282585545e-06]]\n",
            "[[-0.11660338]\n",
            " [ 3.55031233]\n",
            " [ 1.25899625]]\n",
            "mse error: 1.9089e-03\n",
            "iter =  2600\n",
            "loss = [[3.0820276850356726e-06]]\n",
            "[[-0.11658448]\n",
            " [ 3.55031434]\n",
            " [ 1.25962815]]\n",
            "mse error: 1.7446e-03\n",
            "iter =  2800\n",
            "loss = [[2.6515468052382558e-06]]\n",
            "[[-0.11655931]\n",
            " [ 3.55032915]\n",
            " [ 1.26041981]]\n",
            "mse error: 1.6148e-03\n",
            "iter =  3000\n",
            "loss = [[2.3292256427167886e-06]]\n",
            "[[-0.11652623]\n",
            " [ 3.55035645]\n",
            " [ 1.26137301]]\n",
            "mse error: 1.5104e-03\n",
            "iter =  3200\n",
            "loss = [[2.0753844082082111e-06]]\n",
            "[[-0.11648421]\n",
            " [ 3.55039516]\n",
            " [ 1.26247969]]\n",
            "mse error: 1.4235e-03\n",
            "iter =  3400\n",
            "loss = [[1.8659806186253557e-06]]\n",
            "[[-0.11643294]\n",
            " [ 3.55044361]\n",
            " [ 1.26372293]]\n",
            "mse error: 1.3483e-03\n",
            "iter =  3600\n",
            "loss = [[1.6882104556395422e-06]]\n",
            "[[-0.1163727 ]\n",
            " [ 3.55049979]\n",
            " [ 1.26507951]]\n",
            "mse error: 1.2818e-03\n",
            "iter =  3800\n",
            "loss = [[1.5355787475317932e-06]]\n",
            "[[-0.11630419]\n",
            " [ 3.55056148]\n",
            " [ 1.26652315]]\n",
            "mse error: 1.2225e-03\n",
            "iter =  4000\n",
            "loss = [[1.4047127555422308e-06]]\n",
            "[[-0.11622834]\n",
            " [ 3.55062652]\n",
            " [ 1.26802743]]\n",
            "mse error: 1.1699e-03\n",
            "iter =  4200\n",
            "loss = [[1.2937435487185681e-06]]\n",
            "[[-0.11614615]\n",
            " [ 3.55069285]\n",
            " [ 1.26956809]]\n",
            "mse error: 1.1236e-03\n",
            "iter =  4400\n",
            "loss = [[1.2014181187028888e-06]]\n",
            "[[-0.11605852]\n",
            " [ 3.55075869]\n",
            " [ 1.27112477]]\n",
            "mse error: 1.0839e-03\n",
            "iter =  4600\n",
            "loss = [[1.1265143395523684e-06]]\n",
            "[[-0.11596622]\n",
            " [ 3.55082252]\n",
            " [ 1.27268225]]\n",
            "mse error: 1.0507e-03\n",
            "iter =  4800\n",
            "loss = [[1.067484578605962e-06]]\n",
            "[[-0.11586978]\n",
            " [ 3.55088325]\n",
            " [ 1.27423145]]\n",
            "mse error: 1.0239e-03\n",
            "iter =  5000\n",
            "loss = [[1.0223253607522964e-06]]\n",
            "[[-0.11576945]\n",
            " [ 3.55094017]\n",
            " [ 1.27576999]]\n",
            "mse error: 1.0030e-03\n",
            "iter =  5200\n",
            "loss = [[9.8864072027989765e-07]]\n",
            "[[-0.1156652 ]\n",
            " [ 3.55099301]\n",
            " [ 1.27730231]]\n",
            "mse error: 9.8720e-04\n",
            "iter =  5400\n",
            "loss = [[9.6383919287299923e-07]]\n",
            "[[-0.11555671]\n",
            " [ 3.5510419 ]\n",
            " [ 1.27883932]]\n",
            "mse error: 9.7540e-04\n",
            "iter =  5600\n",
            "loss = [[9.45389306281087e-07]]\n",
            "[[-0.11544336]\n",
            " [ 3.5510873 ]\n",
            " [ 1.28039756]]\n",
            "mse error: 9.6652e-04\n",
            "iter =  5800\n",
            "loss = [[9.310557906560104e-07]]\n",
            "[[-0.11532433]\n",
            " [ 3.55112993]\n",
            " [ 1.28199823]]\n",
            "mse error: 9.5953e-04\n",
            "iter =  6000\n",
            "loss = [[9.19054625431605e-07]]\n",
            "[[-0.11519856]\n",
            " [ 3.55117063]\n",
            " [ 1.28366582]]\n",
            "mse error: 9.5357e-04\n",
            "iter =  6200\n",
            "loss = [[9.0809962740896144e-07]]\n",
            "[[-0.11506487]\n",
            " [ 3.55121028]\n",
            " [ 1.28542691]]\n",
            "mse error: 9.4804e-04\n",
            "iter =  6400\n",
            "loss = [[8.9735361174709782e-07]]\n",
            "[[-0.11492196]\n",
            " [ 3.55124971]\n",
            " [ 1.28730878]]\n",
            "mse error: 9.4252e-04\n",
            "iter =  6600\n",
            "loss = [[8.8632447088097348e-07]]\n",
            "[[-0.11476848]\n",
            " [ 3.55128963]\n",
            " [ 1.2893383 ]]\n",
            "mse error: 9.3678e-04\n",
            "iter =  6800\n",
            "loss = [[8.7475065372658752e-07]]\n",
            "[[-0.11460306]\n",
            " [ 3.55133059]\n",
            " [ 1.29154105]]\n",
            "mse error: 9.3070e-04\n",
            "iter =  7000\n",
            "loss = [[8.62506290912203e-07]]\n",
            "[[-0.1144244 ]\n",
            " [ 3.55137294]\n",
            " [ 1.29394086]]\n",
            "mse error: 9.2421e-04\n",
            "iter =  7200\n",
            "loss = [[8.4953680044040658e-07]]\n",
            "[[-0.11423118]\n",
            " [ 3.55141691]\n",
            " [ 1.29655984]]\n",
            "mse error: 9.1728e-04\n",
            "iter =  7400\n",
            "loss = [[8.3582189551182815e-07]]\n",
            "[[-0.11402214]\n",
            " [ 3.55146261]\n",
            " [ 1.29941872]]\n",
            "mse error: 9.0990e-04\n",
            "iter =  7600\n",
            "loss = [[8.213574496550866e-07]]\n",
            "[[-0.11379599]\n",
            " [ 3.5515101 ]\n",
            " [ 1.30253751]]\n",
            "mse error: 9.0205e-04\n",
            "iter =  7800\n",
            "loss = [[8.0614803750718425e-07]]\n",
            "[[-0.11355139]\n",
            " [ 3.55155946]\n",
            " [ 1.30593608]]\n",
            "mse error: 8.9371e-04\n",
            "iter =  8000\n",
            "loss = [[7.9020450047036554e-07]]\n",
            "[[-0.11328691]\n",
            " [ 3.5516108 ]\n",
            " [ 1.3096347 ]]\n",
            "mse error: 8.8489e-04\n",
            "iter =  8200\n",
            "loss = [[7.7354337036174816e-07]]\n",
            "[[-0.11300097]\n",
            " [ 3.55166431]\n",
            " [ 1.31365424]]\n",
            "mse error: 8.7557e-04\n",
            "iter =  8400\n",
            "loss = [[7.5618669769583183e-07]]\n",
            "[[-0.11269183]\n",
            " [ 3.55172029]\n",
            " [ 1.31801621]]\n",
            "mse error: 8.6575e-04\n",
            "iter =  8600\n",
            "loss = [[7.3816177748928014e-07]]\n",
            "[[-0.11235753]\n",
            " [ 3.55177911]\n",
            " [ 1.3227427 ]]\n",
            "mse error: 8.5543e-04\n",
            "iter =  8800\n",
            "loss = [[7.1950067502789064e-07]]\n",
            "[[-0.11199582]\n",
            " [ 3.5518413 ]\n",
            " [ 1.32785622]]\n",
            "mse error: 8.4461e-04\n",
            "iter =  9000\n",
            "loss = [[7.0023958275595138e-07]]\n",
            "[[-0.11160415]\n",
            " [ 3.5519075 ]\n",
            " [ 1.33337955]]\n",
            "mse error: 8.3329e-04\n",
            "iter =  9200\n",
            "loss = [[6.8041806781979912e-07]]\n",
            "[[-0.11117958]\n",
            " [ 3.55197851]\n",
            " [ 1.33933558]]\n",
            "mse error: 8.2147e-04\n",
            "iter =  9400\n",
            "loss = [[6.6007827914649808e-07]]\n",
            "[[-0.11071869]\n",
            " [ 3.55205529]\n",
            " [ 1.34574719]]\n",
            "mse error: 8.0915e-04\n",
            "iter =  9600\n",
            "loss = [[6.3926419420640371e-07]]\n",
            "[[-0.11021753]\n",
            " [ 3.552139  ]\n",
            " [ 1.35263695]]\n",
            "mse error: 7.9634e-04\n",
            "iter =  9800\n",
            "loss = [[6.1802099748964263e-07]]\n",
            "[[-0.10967149]\n",
            " [ 3.55223099]\n",
            " [ 1.36002686]]\n",
            "mse error: 7.8304e-04\n",
            "iter =  10000\n",
            "loss = [[5.9639468716651791e-07]]\n",
            "[[-0.10907514]\n",
            " [ 3.55233286]\n",
            " [ 1.36793791]]\n",
            "mse error: 7.6927e-04\n",
            "iter =  10200\n",
            "loss = [[5.7443199637096367e-07]]\n",
            "[[-0.10842212]\n",
            " [ 3.55244649]\n",
            " [ 1.3763895 ]]\n",
            "mse error: 7.5501e-04\n",
            "iter =  10400\n",
            "loss = [[5.521806899625202e-07]]\n",
            "[[-0.10770489]\n",
            " [ 3.55257409]\n",
            " [ 1.38539876]]\n",
            "mse error: 7.4028e-04\n",
            "iter =  10600\n",
            "loss = [[5.2969026184490215e-07]]\n",
            "[[-0.10691449]\n",
            " [ 3.5527183 ]\n",
            " [ 1.39497953]]\n",
            "mse error: 7.2508e-04\n",
            "iter =  10800\n",
            "loss = [[5.0701302299993763e-07]]\n",
            "[[-0.10604023]\n",
            " [ 3.55288226]\n",
            " [ 1.40514124]]\n",
            "mse error: 7.0942e-04\n",
            "iter =  11000\n",
            "loss = [[4.8420555298820409e-07]]\n",
            "[[-0.10506922]\n",
            " [ 3.55306977]\n",
            " [ 1.4158875 ]]\n",
            "mse error: 6.9331e-04\n",
            "iter =  11200\n",
            "loss = [[4.6133050881109128e-07]]\n",
            "[[-0.10398585]\n",
            " [ 3.55328544]\n",
            " [ 1.42721445]]\n",
            "mse error: 6.7676e-04\n",
            "iter =  11400\n",
            "loss = [[4.3845886721283211e-07]]\n",
            "[[-0.10277109]\n",
            " [ 3.55353489]\n",
            " [ 1.43910893]]\n",
            "mse error: 6.5980e-04\n",
            "iter =  11600\n",
            "loss = [[4.1567283970957416e-07]]\n",
            "[[-0.10140152]\n",
            " [ 3.55382501]\n",
            " [ 1.4515465 ]]\n",
            "mse error: 6.4246e-04\n",
            "iter =  11800\n",
            "loss = [[3.9306995418696617e-07]]\n",
            "[[-0.0998482 ]\n",
            " [ 3.55416421]\n",
            " [ 1.46448934]]\n",
            "mse error: 6.2477e-04\n",
            "iter =  12000\n",
            "loss = [[3.707691230796685e-07]]\n",
            "[[-0.09807506]\n",
            " [ 3.55456274]\n",
            " [ 1.4778841 ]]\n",
            "mse error: 6.0682e-04\n",
            "iter =  12200\n",
            "loss = [[3.4891980570772542e-07]]\n",
            "[[-0.09603702]\n",
            " [ 3.55503299]\n",
            " [ 1.49165993]]\n",
            "mse error: 5.8869e-04\n",
            "iter =  12400\n",
            "loss = [[3.2771526381746376e-07]]\n",
            "[[-0.09367768]\n",
            " [ 3.5555897 ]\n",
            " [ 1.50572655]]\n",
            "mse error: 5.7055e-04\n",
            "iter =  12600\n",
            "loss = [[3.0740947980575681e-07]]\n",
            "[[-0.09092703]\n",
            " [ 3.55624995]\n",
            " [ 1.51997273]]\n",
            "mse error: 5.5262e-04\n",
            "iter =  12800\n",
            "loss = [[2.8833269417751076e-07]]\n",
            "[[-0.08770006]\n",
            " [ 3.55703259]\n",
            " [ 1.53426522]]\n",
            "mse error: 5.3521e-04\n",
            "iter =  13000\n",
            "loss = [[2.7089048327235319e-07]]\n",
            "[[-0.08389856]\n",
            " [ 3.5579566 ]\n",
            " [ 1.5484491 ]]\n",
            "mse error: 5.1878e-04\n",
            "iter =  13200\n",
            "loss = [[4.8696760279311417e-07]]\n",
            "[[-0.07941144]\n",
            " [ 3.55903729]\n",
            " [ 1.5629934 ]]\n",
            "mse error: 5.0453e-04\n",
            "iter =  13400\n",
            "loss = [[2.5474870108488882e-07]]\n",
            "[[-0.07419811]\n",
            " [ 3.56025993]\n",
            " [ 1.57774075]]\n",
            "mse error: 4.9401e-04\n",
            "iter =  13600\n",
            "loss = [[2.379382062272267e-07]]\n",
            "[[-0.06833522]\n",
            " [ 3.56158888]\n",
            " [ 1.59142703]]\n",
            "mse error: 4.8351e-04\n",
            "iter =  13800\n",
            "loss = [[2.2857711524232053e-07]]\n",
            "[[-0.06184318]\n",
            " [ 3.56300211]\n",
            " [ 1.60458562]]\n",
            "mse error: 4.7593e-04\n",
            "iter =  14000\n",
            "loss = [[2.2201444338850935e-07]]\n",
            "[[-0.05478825]\n",
            " [ 3.56447203]\n",
            " [ 1.61733257]]\n",
            "mse error: 4.6925e-04\n",
            "iter =  14200\n",
            "loss = [[2.1634576824244571e-07]]\n",
            "[[-0.04729996]\n",
            " [ 3.56596066]\n",
            " [ 1.62969385]]\n",
            "mse error: 4.6356e-04\n",
            "iter =  14400\n",
            "loss = [[3.8262408952394126e-07]]\n",
            "[[-0.03957156]\n",
            " [ 3.56742118]\n",
            " [ 1.64172853]]\n",
            "mse error: 5.2577e-04\n",
            "iter =  14600\n",
            "loss = [[2.1633696231731385e-07]]\n",
            "[[-0.0318017 ]\n",
            " [ 3.56880504]\n",
            " [ 1.65381295]]\n",
            "mse error: 4.6841e-04\n",
            "iter =  14800\n",
            "loss = [[2.0478418953176264e-07]]\n",
            "[[-0.02420088]\n",
            " [ 3.57006952]\n",
            " [ 1.66582321]]\n",
            "mse error: 4.5345e-04\n",
            "iter =  15000\n",
            "loss = [[2.0205578189881733e-07]]\n",
            "[[-0.01688803]\n",
            " [ 3.57119656]\n",
            " [ 1.67794771]]\n",
            "mse error: 4.4759e-04\n",
            "iter =  15200\n",
            "loss = [[2.5937794597819017e-07]]\n",
            "[[-0.0099749 ]\n",
            " [ 3.57217135]\n",
            " [ 1.69018312]]\n",
            "mse error: 4.5046e-04\n",
            "iter =  15400\n",
            "loss = [[2.0657362991295825e-07]]\n",
            "[[-3.55161079e-03]\n",
            " [ 3.57297832e+00]\n",
            " [ 1.70272154e+00]]\n",
            "mse error: 4.4119e-04\n",
            "iter =  15600\n",
            "loss = [[2.3032686849396118e-07]]\n",
            "[[2.34002928e-03]\n",
            " [3.57361479e+00]\n",
            " [1.71577859e+00]]\n",
            "mse error: 4.3701e-04\n",
            "iter =  15800\n",
            "loss = [[1.9015519768968527e-07]]\n",
            "[[0.00770471]\n",
            " [3.57408306]\n",
            " [1.72911359]]\n",
            "mse error: 4.3554e-04\n",
            "iter =  16000\n",
            "loss = [[2.1381951552883462e-07]]\n",
            "[[0.01253579]\n",
            " [3.57438433]\n",
            " [1.74325004]]\n",
            "mse error: 4.4486e-04\n",
            "iter =  16200\n",
            "loss = [[1.8414877967625523e-07]]\n",
            "[[0.01687667]\n",
            " [3.5745259 ]\n",
            " [1.75777494]]\n",
            "mse error: 4.2925e-04\n",
            "iter =  16400\n",
            "loss = [[2.1180172751658146e-07]]\n",
            "[[0.02074779]\n",
            " [3.57451032]\n",
            " [1.77306004]]\n",
            "mse error: 4.2906e-04\n",
            "iter =  16600\n",
            "loss = [[1.8156027183178254e-07]]\n",
            "[[0.02420332]\n",
            " [3.57434347]\n",
            " [1.78896607]]\n",
            "mse error: 4.2435e-04\n",
            "iter =  16800\n",
            "loss = [[1.7905018350844276e-07]]\n",
            "[[0.02730001]\n",
            " [3.57403068]\n",
            " [1.80557159]]\n",
            "mse error: 4.1702e-04\n",
            "iter =  17000\n",
            "loss = [[1.8833880966450121e-07]]\n",
            "[[0.0301086 ]\n",
            " [3.57357808]\n",
            " [1.82286606]]\n",
            "mse error: 4.1369e-04\n",
            "iter =  17200\n",
            "loss = [[1.9646353949077854e-07]]\n",
            "[[0.03270491]\n",
            " [3.57299141]\n",
            " [1.84080041]]\n",
            "mse error: 4.1131e-04\n",
            "iter =  17400\n",
            "loss = [[2.0491050133011756e-07]]\n",
            "[[0.03516623]\n",
            " [3.57227564]\n",
            " [1.8593104 ]]\n",
            "mse error: 4.0996e-04\n",
            "iter =  17600\n",
            "loss = [[1.948066243302889e-07]]\n",
            "[[0.03757084]\n",
            " [3.57143508]\n",
            " [1.87830963]]\n",
            "mse error: 4.0610e-04\n",
            "iter =  17800\n",
            "loss = [[1.6302633064830253e-07]]\n",
            "[[0.03999743]\n",
            " [3.57047345]\n",
            " [1.89769982]]\n",
            "mse error: 3.9724e-04\n",
            "iter =  18000\n",
            "loss = [[1.74443608794776e-07]]\n",
            "[[0.04253015]\n",
            " [3.56939495]\n",
            " [1.91764739]]\n",
            "mse error: 3.9592e-04\n",
            "iter =  18200\n",
            "loss = [[1.6647848417846857e-07]]\n",
            "[[0.04523915]\n",
            " [3.5682045 ]\n",
            " [1.93765172]]\n",
            "mse error: 3.9207e-04\n",
            "iter =  18400\n",
            "loss = [[1.8336072078622555e-07]]\n",
            "[[0.04817968]\n",
            " [3.56690372]\n",
            " [1.95748343]]\n",
            "mse error: 3.9098e-04\n",
            "iter =  18600\n",
            "loss = [[1.7015398064428321e-07]]\n",
            "[[0.05140956]\n",
            " [3.56549349]\n",
            " [1.97711722]]\n",
            "mse error: 3.8821e-04\n",
            "iter =  18800\n",
            "loss = [[1.64920524249478e-07]]\n",
            "[[0.05499576]\n",
            " [3.56397535]\n",
            " [1.99654457]]\n",
            "mse error: 3.7806e-04\n",
            "iter =  19000\n",
            "loss = [[1.6052545235332663e-07]]\n",
            "[[0.05900781]\n",
            " [3.56235141]\n",
            " [2.01577441]]\n",
            "mse error: 3.7328e-04\n",
            "iter =  19200\n",
            "loss = [[1.4880683520206781e-07]]\n",
            "[[0.06349924]\n",
            " [3.56062318]\n",
            " [2.03444117]]\n",
            "mse error: 3.7269e-04\n",
            "iter =  19400\n",
            "loss = [[1.4610761742170368e-07]]\n",
            "[[0.06850448]\n",
            " [3.55879044]\n",
            " [2.05244439]]\n",
            "mse error: 3.6075e-04\n",
            "iter =  19600\n",
            "loss = [[1.6100523317154704e-07]]\n",
            "[[0.07406134]\n",
            " [3.55685277]\n",
            " [2.06982344]]\n",
            "mse error: 3.6019e-04\n",
            "iter =  19800\n",
            "loss = [[1.2916476332710077e-07]]\n",
            "[[0.08021457]\n",
            " [3.5548101 ]\n",
            " [2.08657154]]\n",
            "mse error: 3.5143e-04\n",
            "iter =  20000\n",
            "loss = [[1.6114151609259247e-07]]\n",
            "[[0.08700669]\n",
            " [3.55266209]\n",
            " [2.10262156]]\n",
            "mse error: 3.5436e-04\n",
            "iter =  20200\n",
            "loss = [[1.4853202110638887e-07]]\n",
            "[[0.09447381]\n",
            " [3.55040775]\n",
            " [2.1179088 ]]\n",
            "mse error: 3.4994e-04\n",
            "iter =  20400\n",
            "loss = [[1.3647337716014981e-07]]\n",
            "[[0.10265129]\n",
            " [3.54804576]\n",
            " [2.13244279]]\n",
            "mse error: 3.4619e-04\n",
            "iter =  20600\n",
            "loss = [[1.4189290643108033e-07]]\n",
            "[[0.11157858]\n",
            " [3.54557463]\n",
            " [2.14624054]]\n",
            "mse error: 3.4303e-04\n",
            "iter =  20800\n",
            "loss = [[1.5146484186168333e-07]]\n",
            "[[0.12130017]\n",
            " [3.54299277]\n",
            " [2.15931216]]\n",
            "mse error: 3.3690e-04\n",
            "iter =  21000\n",
            "loss = [[1.1718313793345571e-07]]\n",
            "[[0.13186656]\n",
            " [3.54029854]\n",
            " [2.17167756]]\n",
            "mse error: 3.2526e-04\n",
            "iter =  21200\n",
            "loss = [[1.4155626234358703e-07]]\n",
            "[[0.14333478]\n",
            " [3.5374903 ]\n",
            " [2.18336467]]\n",
            "mse error: 3.2697e-04\n",
            "iter =  21400\n",
            "loss = [[1.0576887358401604e-07]]\n",
            "[[0.15577062]\n",
            " [3.53456661]\n",
            " [2.19444326]]\n",
            "mse error: 3.1778e-04\n",
            "iter =  21600\n",
            "loss = [[1.1232871808674071e-07]]\n",
            "[[0.16925104]\n",
            " [3.53152647]\n",
            " [2.20488922]]\n",
            "mse error: 3.1249e-04\n",
            "iter =  21800\n",
            "loss = [[1.253315437053185e-07]]\n",
            "[[0.18385815]\n",
            " [3.52836931]\n",
            " [2.21474821]]\n",
            "mse error: 3.0875e-04\n",
            "iter =  22000\n",
            "loss = [[1.2572356454140292e-07]]\n",
            "[[0.19968351]\n",
            " [3.52509554]\n",
            " [2.22408114]]\n",
            "mse error: 3.0662e-04\n",
            "iter =  22200\n",
            "loss = [[1.1613567254187819e-07]]\n",
            "[[0.21682341]\n",
            " [3.52170681]\n",
            " [2.23286265]]\n",
            "mse error: 2.9919e-04\n",
            "iter =  22400\n",
            "loss = [[9.9156636883096443e-08]]\n",
            "[[0.23537653]\n",
            " [3.5182065 ]\n",
            " [2.24117364]]\n",
            "mse error: 2.9341e-04\n",
            "iter =  22600\n",
            "loss = [[8.8825991295689049e-08]]\n",
            "[[0.2554397 ]\n",
            " [3.51460036]\n",
            " [2.24901333]]\n",
            "mse error: 2.8910e-04\n",
            "iter =  22800\n",
            "loss = [[1.0167351358253048e-07]]\n",
            "[[0.27710202]\n",
            " [3.51089718]\n",
            " [2.2564049 ]]\n",
            "mse error: 2.8700e-04\n",
            "iter =  23000\n",
            "loss = [[1.2111809262184543e-07]]\n",
            "[[0.30043812]\n",
            " [3.50710966]\n",
            " [2.26342366]]\n",
            "mse error: 2.8896e-04\n",
            "iter =  23200\n",
            "loss = [[1.2865383410437404e-07]]\n",
            "[[0.32549679]\n",
            " [3.50325527]\n",
            " [2.27002048]]\n",
            "mse error: 2.8159e-04\n",
            "iter =  23400\n",
            "loss = [[1.1792445121860451e-07]]\n",
            "[[0.35229132]\n",
            " [3.49935733]\n",
            " [2.27631149]]\n",
            "mse error: 2.7629e-04\n",
            "iter =  23600\n",
            "loss = [[1.0616714576085767e-07]]\n",
            "[[0.38078793]\n",
            " [3.49544616]\n",
            " [2.28224096]]\n",
            "mse error: 2.6634e-04\n",
            "iter =  23800\n",
            "loss = [[1.1649721218309632e-07]]\n",
            "[[0.4108957 ]\n",
            " [3.49156036]\n",
            " [2.28790778]]\n",
            "mse error: 2.7115e-04\n",
            "iter =  24000\n",
            "loss = [[1.0930746755043868e-07]]\n",
            "[[0.44245317]\n",
            " [3.48774776]\n",
            " [2.29324994]]\n",
            "mse error: 2.6273e-04\n",
            "iter =  24200\n",
            "loss = [[7.0001506758630119e-08]]\n",
            "[[0.47520256]\n",
            " [3.48406459]\n",
            " [2.29835903]]\n",
            "mse error: 2.5088e-04\n",
            "iter =  24400\n",
            "loss = [[1.02480488048099e-07]]\n",
            "[[0.50877874]\n",
            " [3.48057412]\n",
            " [2.30320591]]\n",
            "mse error: 2.5440e-04\n",
            "iter =  24600\n",
            "loss = [[9.8277852885022991e-08]]\n",
            "[[0.54271304]\n",
            " [3.47734513]\n",
            " [2.30779365]]\n",
            "mse error: 2.4803e-04\n",
            "iter =  24800\n",
            "loss = [[7.1848281144797486e-08]]\n",
            "[[0.57644554]\n",
            " [3.47444893]\n",
            " [2.31219111]]\n",
            "mse error: 2.3806e-04\n",
            "iter =  25000\n",
            "loss = [[9.6874050915797379e-08]]\n",
            "[[0.60934726]\n",
            " [3.47195465]\n",
            " [2.31639131]]\n",
            "mse error: 2.4295e-04\n",
            "iter =  25200\n",
            "loss = [[9.3578200601975175e-08]]\n",
            "[[0.64075745]\n",
            " [3.46992332]\n",
            " [2.32038637]]\n",
            "mse error: 2.3573e-04\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-4ed302246a48>\u001b[0m in \u001b[0;36m<cell line: 27>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m   \u001b[0;31m# compute gradients using AD\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m   \u001b[0mloss_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgrad_param\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPINN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mxcl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mycl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mxmeas\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mymeas\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtmeas\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m   \u001b[0;31m# update neural network weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 832\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 877\u001b[0;31m       results = tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    878\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1321\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1322\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1485\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1486\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1487\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1488\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# residual computation based on AD\n",
        "@tf.function\n",
        "def r_PINN(x,y,param):\n",
        "    u = PINN(tf.concat([x,y], 1))\n",
        "    u_x = tf.gradients(u,x)[0]\n",
        "    u_y = tf.gradients(u,y)[0]\n",
        "    u_grad = tf.transpose(tf.concat([u_x, u_y], axis=1))\n",
        "\n",
        "    theta0 = pi/2 - param[0]\n",
        "    a = tf.stack([tf.cos(theta0), tf.sin(theta0)])\n",
        "    b = tf.stack([tf.cos(theta0-pi/2), tf.sin(theta0-pi/2)])\n",
        "\n",
        "    D = ((1/param[1])* tf.linalg.matmul(a,tf.transpose(a)) + tf.linalg.matmul(b,tf.transpose(b)))\n",
        "\n",
        "    return  tf.linalg.matmul(tf.transpose(u_grad), tf.linalg.matmul(D,u_grad)) - 1/100**2 #check gradient shape\n",
        "\n",
        "# Adam optimizer\n",
        "tf_optimizer = tf.keras.optimizers.Adam(learning_rate=0.003,beta_1=0.99)\n",
        "\n",
        "# parameter variable try ( 1.45816415][ 3.84494007][-0.95064015]])\n",
        "#param 0 -> fiber anlge (-pi/10,pi/10)\n",
        "#param 1-> aniso (0,1)\n",
        "#param 2-> source y0 (-1.5,1,5)\n",
        "pi = tf.constant(np.pi,dtype=tf.float64)\n",
        "param = tf.Variable([[0.01], [3], [1.5]], trainable=True,dtype=tf.float64)\n",
        "\n",
        "for iter in range(50000):\n",
        "\n",
        "  # compute gradients using AD\n",
        "  loss_value,grads,grad_param = grad(PINN,xcl,ycl,xmeas,ymeas,tmeas,param)\n",
        "\n",
        "  # update neural network weights\n",
        "  tf_optimizer.apply_gradients(zip(grads+[grad_param],PINN.trainable_variables+[param]))\n",
        "\n",
        "  # display intermediate results\n",
        "  if ((iter+1) % 200 == 0):\n",
        "    print('iter =  '+str(iter+1))\n",
        "    #loss_value_np=loss_value.numpy()\n",
        "    #print('loss = {:.4f}'.format(loss_value_np ))\n",
        "    tf.print('loss =' , loss_value)\n",
        "\n",
        "    print(param.numpy())\n",
        "    PINN_flat = PINN(X_flat)\n",
        "\n",
        "    mse = 0.0\n",
        "    time_pred = tf.reshape(PINN_flat, (1501, 1501))\n",
        "    time_pred = time_pred.numpy()\n",
        "    xmeas=xmeas.numpy().squeeze()\n",
        "    ymeas=ymeas.numpy().squeeze()\n",
        "    tmeas=tmeas.numpy().squeeze()\n",
        "\n",
        "    for k in range(20):\n",
        "            i, j = np.where((X == xmeas[k]) & (Y == ymeas[k]))\n",
        "            mse+= (time_pred[i, j] - tmeas[k]) ** 2\n",
        "\n",
        "    print('mse error: %.4e' % (np.sqrt(mse/20)))\n",
        "\n",
        "    xmeas = tf.constant(xmeas.reshape(20, 1), dtype=tf.float64)\n",
        "    ymeas = tf.constant(ymeas.reshape(20, 1), dtype=tf.float64)\n",
        "    tmeas = tf.constant(tmeas.reshape(20, 1), dtype=tf.float64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xjbpEPkfWDJe"
      },
      "outputs": [],
      "source": [
        "#Display results\n",
        "\n",
        "N_h = 150\n",
        "X_plot, Y_plot = np.meshgrid(np.linspace(-1.5,1.5,1501), np.linspace(-1.5,1.5,1501))\n",
        "\n",
        "fig = plt.figure(figsize=(16,9),dpi=150)\n",
        "#fig = plt.figure()\n",
        "#fig.subplots_adjust(wspace=0.3)\n",
        "plt.style.use('default')\n",
        "ax = fig.add_subplot(1,3,1)\n",
        "ax.set_aspect(1)\n",
        "im = plt.pcolor(X_plot, Y_plot, u_true)\n",
        "plt.scatter(xmeas,ymeas,marker='x',s=3)\n",
        "divider = make_axes_locatable(ax)\n",
        "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
        "fig.colorbar(im,cax=cax)\n",
        "#ax.set_yticklabels(['-1.0','-0.6','-0.2','0.2','0.6','1.0'])\n",
        "ax.set_title('Exact Solution',fontsize=16)\n",
        "\n",
        "ax = fig.add_subplot(1,3,2)\n",
        "ax.set_aspect(1)\n",
        "im = plt.pcolor(X_plot, Y_plot, np.reshape(PINN_flat,(N_h,N_h)))\n",
        "plt.scatter(xmeas,ymeas,marker='x',s=3)\n",
        "divider = make_axes_locatable(ax)\n",
        "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
        "fig.colorbar(im,cax=cax)\n",
        "ax.set_title('PINN Prediction'.format(err),fontsize=16)\n",
        "\n",
        "ax = fig.add_subplot(1,3,3)\n",
        "ax.set_aspect(1)\n",
        "im = plt.pcolor(X_plot, Y_plot, np.abs( np.reshape(PINN_flat,(N_h,N_h)) -u_true ) )\n",
        "divider = make_axes_locatable(ax)\n",
        "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
        "fig.colorbar(im,cax=cax)\n",
        "ax.set_title('L2 error = {:.4f}'.format(err),fontsize=16)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}