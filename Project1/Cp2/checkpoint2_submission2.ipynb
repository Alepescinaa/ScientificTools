{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Alepescinaa/ScientificTools/blob/main/Project1/Cp2/checkpoint2_submission2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9QxtRkHFzOQi"
      },
      "source": [
        "# Exercises: physics-informed neural network\n",
        "\n",
        "Exercise on the implementation of physics-informed neural network.\n",
        "\n",
        "Date: 2024\n",
        "\n",
        "Course: 056936 - SCIENTIFIC COMPUTING TOOLS FOR ADVANCED MATHEMATICAL MODELLING (PAGANI STEFANO) [2023-24].\n",
        "\n",
        "Example adapted from this [notebook](https://colab.research.google.com/drive/1qBrbgevkSBqqYc8bOPiaoJG1MBrBrluN?usp=share_link)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-vC4ZgNMNSA"
      },
      "source": [
        "\n",
        "Let us consider the problem\n",
        "\n",
        "\\begin{aligned}\n",
        "  & v_f *\\sqrt(\\nabla u\\cdot D\\nabla u) =1  \\,, \\quad (x,y) \\in [-1.5,1.5] \\times [-1.5,1.5]\\,\\\\\n",
        "\\end{aligned}\n",
        "\n",
        "where $\\nu$ is unknown. We consider the PINN framework for solving the state/parameter estimation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "XJzSWQcWh85s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99786bdb-d794-4a17-d195-80e3c36c83bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pyDOE (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "# import required libraries\n",
        "\n",
        "import scipy.io\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
        "\n",
        "!pip -q install pyDOE\n",
        "from pyDOE import lhs"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Alepescinaa/ScientificTools\n",
        "%cd ScientificTools/Project1/Cp2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TI8--dd2xQrh",
        "outputId": "e9515b1b-6f39-414d-8ea2-a19e0b68a38f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ScientificTools'...\n",
            "remote: Enumerating objects: 539, done.\u001b[K\n",
            "remote: Counting objects: 100% (383/383), done.\u001b[K\n",
            "remote: Compressing objects: 100% (299/299), done.\u001b[K\n",
            "remote: Total 539 (delta 129), reused 226 (delta 68), pack-reused 156\u001b[K\n",
            "Receiving objects: 100% (539/539), 129.20 MiB | 14.38 MiB/s, done.\n",
            "Resolving deltas: 100% (167/167), done.\n",
            "Updating files: 100% (24/24), done.\n",
            "/content/ScientificTools/Project1/Cp2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# loading of the dataset\n",
        "\n",
        "CP2data = np.load(\"CP2data.npz\")\n",
        "CP2data = CP2data['arr_0']"
      ],
      "metadata": {
        "id": "Gxj4yRs1xsL8"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "iPZ7AMmXMNSB"
      },
      "outputs": [],
      "source": [
        "# set seed for reproducibility\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# collocation points\n",
        "Ncl = 20000\n",
        "Xcl = lhs(2,Ncl)\n",
        "xcl = tf.expand_dims(tf.cast(-1.5+(3.0)*Xcl[:,0],dtype=tf.float64),axis=-1)\n",
        "ycl = tf.expand_dims(tf.cast(-1.5+(3.0)*Xcl[:,1],dtype=tf.float64),axis=-1)\n",
        "X_coll = tf.concat([xcl,ycl],1)"
      ],
      "metadata": {
        "id": "IFVuxND0vKWt"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "wqZ_fC-1KON_"
      },
      "outputs": [],
      "source": [
        "def penalty(param, lower_bound, upper_bound):\n",
        "    return tf.reduce_sum(tf.square(tf.maximum(param - upper_bound, 0)) +\n",
        "                         tf.square(tf.maximum(lower_bound - param, 0)))\n",
        "# PINN loss function\n",
        "def loss(xcl,ycl,xmeas,ymeas,umeas,theta_fiber,a_ratio,y0):\n",
        "    input_data=tf.concat([xmeas,ymeas],1)\n",
        "    umeas_pred = PINN(input_data)\n",
        "    r_pred   = r_PINN(xcl,ycl,theta_fiber,a_ratio)\n",
        "\n",
        "    # loss components\n",
        "    mse_meas  = tf.reduce_mean(tf.pow(umeas-umeas_pred,2))\n",
        "    mse_r  = tf.reduce_mean(tf.abs(r_pred))\n",
        "\n",
        "    # bc\n",
        "    param_2= -1.5+(1.5+1.5)*y0\n",
        "    mse_bc= tf.pow( PINN( tf.transpose( tf.stack( [tf.constant([1.5],dtype=tf.float64), param_2] ) ) ) ,2)\n",
        "\n",
        "    #penalty over param boundaries\n",
        "    mse_penalty = penalty(theta_fiber,0,1)+penalty(a_ratio,0,1)+penalty(y0,0,1)\n",
        "\n",
        "    #tf.print('mse_time',mse_meas)\n",
        "    #tf.print('mse_param',mse_r)\n",
        "    #tf.print('mse_bc',mse_bc)\n",
        "    return mse_meas + 2*mse_r + 2*mse_bc + mse_penalty\n",
        "\n",
        "\n",
        "# residual computation based on AD\n",
        "@tf.function\n",
        "def r_PINN(x,y,theta_fiber,a_ratio):\n",
        "    input_data=tf.concat([x,y],1)\n",
        "    u = PINN(input_data)\n",
        "    u_x = tf.gradients(u,x)[0]\n",
        "    u_y = tf.gradients(u,y)[0]\n",
        "    u_grad = tf.transpose(tf.concat([u_x, u_y], axis=1))\n",
        "\n",
        "    pi = tf.constant(np.pi,dtype=tf.float64)\n",
        "    param_0=-np.pi/10+(np.pi/10+np.pi/10)*theta_fiber\n",
        "    param_1=1+(9-1)*a_ratio\n",
        "    theta0 = pi/2 - param_0\n",
        "    a = tf.stack([tf.cos(theta0), tf.sin(theta0)])\n",
        "    b = tf.stack([tf.cos(theta0-pi/2), tf.sin(theta0-pi/2)])\n",
        "\n",
        "    #D = ((1/param[1])* tf.linalg.matmul(a,tf.transpose(a)) + tf.linalg.matmul(b,tf.transpose(b)))\n",
        "    #return  tf.linalg.matmul(tf.transpose(u_grad), tf.linalg.matmul(D,u_grad)) - 1/100**2\n",
        "    D_00 = 1 / param_1 * a[0]**2 + b[0]**2\n",
        "    D_01 = 1 / param_1 * a[0] * a[1] + b[0] * b[1]\n",
        "    D_10 = 1 / param_1 * a[0] * a[1] + b[0] * b[1]\n",
        "    D_11 = 1 / param_1 * a[1]**2 + b[1]**2\n",
        "\n",
        "    return ((u_x * D_00 * u_x + u_x * D_01 * u_y + u_y * D_10 * u_x + u_y * D_11 * u_y))  - 1/100**2\n",
        "\n",
        "\n",
        "# neural network weight gradients\n",
        "@tf.function\n",
        "def grad(model,xcl,ycl,xmeas,ymeas,umeas,theta_fiber,a_ratio,y0):\n",
        "    with tf.GradientTape(persistent=True) as tape:\n",
        "        loss_value = loss(xcl,ycl,xmeas,ymeas,umeas,theta_fiber,a_ratio,y0)\n",
        "        grads = tape.gradient(loss_value,model.trainable_variables)\n",
        "        grad_tf = tape.gradient(loss_value,theta_fiber)\n",
        "        grad_ar = tape.gradient(loss_value,a_ratio)\n",
        "        grad_y0 = tape.gradient(loss_value,y0)\n",
        "    return loss_value, grads, grad_tf, grad_ar, grad_y0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "z_cOmQDHKX4k"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.layers import LSTM\n",
        "\n",
        "\n",
        "regularization_strength = 1e-3\n",
        "\n",
        "PINN = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(64, activation='relu', input_shape=(2,),\n",
        "                          kernel_initializer=\"glorot_uniform\",\n",
        "                          kernel_regularizer=regularizers.l2(regularization_strength),\n",
        "                          dtype=tf.float64),\n",
        "     tf.keras.layers.BatchNormalization(),\n",
        "\n",
        "    tf.keras.layers.Reshape((1, 64)),\n",
        "\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(units = 64)),\n",
        "\n",
        "    tf.keras.layers.Dense(128, activation='relu',\n",
        "                          kernel_initializer=\"glorot_uniform\",\n",
        "                          kernel_regularizer=regularizers.l2(regularization_strength),\n",
        "                          dtype=tf.float64),\n",
        "     tf.keras.layers.BatchNormalization(),\n",
        "\n",
        "    tf.keras.layers.Dense(32, activation='relu',\n",
        "                          kernel_initializer=\"glorot_uniform\",\n",
        "                          kernel_regularizer=regularizers.l2(regularization_strength),\n",
        "                          dtype=tf.float64),\n",
        "     tf.keras.layers.BatchNormalization(),\n",
        "\n",
        "    tf.keras.layers.Dense(1, activation=None,\n",
        "                          kernel_initializer=\"glorot_uniform\",\n",
        "                          kernel_regularizer=regularizers.l2(regularization_strength),\n",
        "                          dtype=tf.float64)\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.interpolate import RBFInterpolator\n",
        "\n",
        "def checkpoint1_solution(x, y, t, X, Y, s_value=0.05, s_aniso_1=0.5, s_aniso_2=0.5):\n",
        "    coordinates = np.column_stack((x, y))\n",
        "\n",
        "    mesh_coordinates=np.column_stack((X.ravel(), Y.ravel()))\n",
        "\n",
        "    s = [s_value,s_value,s_value,s_value,s_value,s_value,s_value,s_value,s_value,s_value,s_aniso_1, s_value,s_value,s_value,s_value, s_aniso_2,s_value,s_value,s_value,s_value]\n",
        "\n",
        "    rbf = RBFInterpolator(coordinates, t, neighbors=None, smoothing=s, kernel='thin_plate_spline', epsilon=None, degree=1)\n",
        "\n",
        "    time_pred = rbf(mesh_coordinates)\n",
        "    time_pred=time_pred.reshape(1501,1501)\n",
        "\n",
        "    return time_pred"
      ],
      "metadata": {
        "id": "rtVF3oVFzkQx"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def checkpoint2_solution( x, y , t ):\n",
        "\n",
        "  xmeas_train, xmeas_val, ymeas_train, ymeas_val, tmeas_train, tmeas_val = train_test_split(x, y, t, test_size=0.1)\n",
        "  xmeas_train = tf.constant(xmeas_train.reshape(18, 1), dtype=tf.float64)\n",
        "  ymeas_train = tf.constant(ymeas_train.reshape(18, 1), dtype=tf.float64)\n",
        "  tmeas_train = tf.constant(tmeas_train.reshape(18, 1), dtype=tf.float64)\n",
        "  xmeas_val = tf.constant(xmeas_val.reshape(2, 1), dtype=tf.float64)\n",
        "  ymeas_val = tf.constant(ymeas_val.reshape(2, 1), dtype=tf.float64)\n",
        "  tmeas_val = tf.constant(tmeas_val.reshape(2, 1), dtype=tf.float64)\n",
        "\n",
        "  X, Y = np.meshgrid(np.linspace(-1.5,1.5,1501), np.linspace(-1.5,1.5,1501))\n",
        "  time_pred = checkpoint1_solution(x, y, t, X, Y, s_value=0.05, s_aniso_1=0.5, s_aniso_2=0.5)\n",
        "  y0_initial = Y[np.where(time_pred==np.min(time_pred))]\n",
        "  y0_initial_scaled=(y0_initial+1.5)/3\n",
        "\n",
        "  theta_fiber = tf.Variable([0.5], trainable=True,dtype=tf.float64)\n",
        "  a_ratio = tf.Variable([0.5], trainable=True,dtype=tf.float64)\n",
        "  y0 = tf.Variable([y0_initial_scaled[0]], trainable=True,dtype=tf.float64)\n",
        "\n",
        "\n",
        "  pinn_optimizer = tf.keras.optimizers.Adam(learning_rate=0.01,beta_1=0.99)\n",
        "  pinn_optimizer.build(PINN.trainable_variables)\n",
        "\n",
        "  param0_optimizer = tf.keras.optimizers.Adam(learning_rate=0.01,beta_1=0.99)\n",
        "  param0_optimizer.build([theta_fiber])\n",
        "\n",
        "  param1_optimizer = tf.keras.optimizers.Adam(learning_rate=0.01,beta_1=0.99)\n",
        "  param1_optimizer.build([a_ratio])\n",
        "\n",
        "  param2_optimizer = tf.keras.optimizers.Adam(learning_rate=0.01,beta_1=0.99)\n",
        "  param2_optimizer.build( [y0])\n",
        "\n",
        "\n",
        "  for iter in range(800):\n",
        "\n",
        "    loss_value,grads,grad_tf, grad_ar, grad_y0 = grad(PINN,xcl,ycl,xmeas_train, ymeas_train, tmeas_train, theta_fiber,a_ratio,y0)\n",
        "\n",
        "    pinn_optimizer.apply_gradients(zip(grads,PINN.trainable_variables))\n",
        "\n",
        "    loss_value_val, _, _,_,_ = grad(PINN, xcl, ycl, xmeas_val, ymeas_val, tmeas_val,theta_fiber,a_ratio,y0)\n",
        "\n",
        "    if ((iter+1) % 100 == 0):\n",
        "      print('iter =  '+str(iter+1))\n",
        "      tf.print('loss =' , loss_value)\n",
        "      tf.print('loss_val_param =' , loss_value_val)\n",
        "\n",
        "      theta_fiber_res= -np.pi/10+np.pi/5*theta_fiber\n",
        "      a_ratio_res=1+8*a_ratio\n",
        "      y0_res=-1.5+3*y0\n",
        "      print(theta_fiber_res.numpy())\n",
        "      print(a_ratio_res.numpy())\n",
        "      print(y0_res.numpy())\n",
        "\n",
        "\n",
        "  for iter in range(800):\n",
        "\n",
        "\n",
        "    loss_value,grads,grad_tf, grad_ar, grad_y0 = grad(PINN,xcl,ycl,xmeas_train, ymeas_train, tmeas_train, theta_fiber,a_ratio,y0)\n",
        "\n",
        "    param0_optimizer.apply_gradients(zip([grad_tf],[theta_fiber]))\n",
        "    pinn_optimizer.apply_gradients(zip(grads,PINN.trainable_variables))\n",
        "\n",
        "    loss_value_val, _, _, _, _ = grad(PINN, xcl, ycl, xmeas_val, ymeas_val, tmeas_val,theta_fiber,a_ratio,y0)\n",
        "\n",
        "\n",
        "    if ((iter+1) % 100 == 0):\n",
        "      print('iter =  '+str(iter+1))\n",
        "      tf.print('loss =' , loss_value)\n",
        "      tf.print('loss_val_param =' , loss_value_val)\n",
        "\n",
        "      theta_fiber_res= -np.pi/10+np.pi/5*theta_fiber\n",
        "      a_ratio_res=1+8*a_ratio\n",
        "      y0_res=-1.5+3*y0\n",
        "      print(theta_fiber_res.numpy())\n",
        "      print(a_ratio_res.numpy())\n",
        "      print(y0_res.numpy())\n",
        "      print()\n",
        "\n",
        "  print()\n",
        "  for iter in range(800):\n",
        "\n",
        "\n",
        "    loss_value,grads,grad_tf, grad_ar, grad_y0 = grad(PINN,xcl,ycl,xmeas_train, ymeas_train, tmeas_train, theta_fiber,a_ratio,y0)\n",
        "\n",
        "    param1_optimizer.apply_gradients(zip([grad_ar],[a_ratio]))\n",
        "    pinn_optimizer.apply_gradients(zip(grads,PINN.trainable_variables))\n",
        "\n",
        "    loss_value_val, _, _, _, _ = grad(PINN, xcl, ycl, xmeas_val, ymeas_val, tmeas_val,theta_fiber,a_ratio,y0)\n",
        "\n",
        "\n",
        "    if ((iter+1) % 100 == 0):\n",
        "      print('iter =  '+str(iter+1))\n",
        "      tf.print('loss =' , loss_value)\n",
        "      tf.print('loss_val_param =' , loss_value_val)\n",
        "\n",
        "      theta_fiber_res= -np.pi/10+np.pi/5*theta_fiber\n",
        "      a_ratio_res=1+8*a_ratio\n",
        "      y0_res=-1.5+3*y0\n",
        "      print(theta_fiber_res.numpy())\n",
        "      print(a_ratio_res.numpy())\n",
        "      print(y0_res.numpy())\n",
        "      print()\n",
        "\n",
        "  print()\n",
        "  for iter in range(800):\n",
        "\n",
        "\n",
        "    loss_value,grads,grad_tf, grad_ar, grad_y0 = grad(PINN,xcl,ycl,xmeas_train, ymeas_train, tmeas_train, theta_fiber,a_ratio,y0)\n",
        "\n",
        "    param2_optimizer.apply_gradients(zip([grad_y0],[y0]))\n",
        "    pinn_optimizer.apply_gradients(zip(grads,PINN.trainable_variables))\n",
        "\n",
        "    loss_value_val, _, _, _, _ = grad(PINN, xcl, ycl, xmeas_val, ymeas_val, tmeas_val,theta_fiber,a_ratio,y0)\n",
        "\n",
        "\n",
        "    if ((iter+1) % 100 == 0):\n",
        "      print('iter =  '+str(iter+1))\n",
        "      tf.print('loss =' , loss_value)\n",
        "      tf.print('loss_val_param =' , loss_value_val)\n",
        "\n",
        "      theta_fiber_res= -np.pi/10+np.pi/5*theta_fiber\n",
        "      a_ratio_res=1+8*a_ratio\n",
        "      y0_res=-1.5+3*y0\n",
        "      print(theta_fiber_res.numpy())\n",
        "      print(a_ratio_res.numpy())\n",
        "      print(y0_res.numpy())\n",
        "      print()\n",
        "  \"\"\"\n",
        "  patience = float('inf')\n",
        "  patience_lr= float('inf')\n",
        "  min_delta = 1e-9\n",
        "  best_val_loss = float('inf')\n",
        "  wait = 0\n",
        "  count = 0\n",
        "  \"\"\"\n",
        "  pinn_optimizer.learning_rate=0.005\n",
        "  param0_optimizer.learning_rate=0.003\n",
        "  param1_optimizer.learning_rate=0.003\n",
        "  param2_optimizer.learning_rate=0.003\n",
        "\n",
        "  print()\n",
        "  for iter in range(5000):\n",
        "\n",
        "\n",
        "    loss_value,grads,grad_tf, grad_ar, grad_y0 = grad(PINN,xcl,ycl,xmeas_train, ymeas_train, tmeas_train, theta_fiber,a_ratio,y0)\n",
        "\n",
        "    pinn_optimizer.apply_gradients(zip(grads,PINN.trainable_variables))\n",
        "    param0_optimizer.apply_gradients(zip([grad_tf],[theta_fiber]))\n",
        "    param1_optimizer.apply_gradients(zip([grad_ar],[a_ratio]))\n",
        "    param2_optimizer.apply_gradients(zip([grad_y0],[y0]))\n",
        "\n",
        "\n",
        "    loss_value_val, _, _,_,_ = grad(PINN, xcl, ycl, xmeas_val, ymeas_val, tmeas_val,theta_fiber,a_ratio,y0)\n",
        "\n",
        "    \"\"\"\n",
        "    best_weigths = None\n",
        "    best_params = None\n",
        "\n",
        "    # Early stopping\n",
        "    if loss_value_val < best_val_loss - min_delta:\n",
        "        best_val_loss = loss_value_val\n",
        "        wait = 0\n",
        "        count = 0\n",
        "        best_weights = PINN.get_weights()\n",
        "        best_params = theta_fiber.numpy()\n",
        "    else:\n",
        "        wait += 1\n",
        "        count += 1\n",
        "\n",
        "        if count >= patience_lr:\n",
        "          tf_optimizer.learning_rate = tf_optimizer.learning_rate * 0.9\n",
        "          count = 0\n",
        "\n",
        "        if wait >= patience:\n",
        "            print('Early stopping at epoch', iter + 1)\n",
        "            break\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    if ((iter+1) % 100 == 0):\n",
        "      print('iter =  '+str(iter+1))\n",
        "      tf.print('loss =' , loss_value)\n",
        "      tf.print('loss_val_param =' , loss_value_val)\n",
        "\n",
        "      theta_fiber_res= -np.pi/10+np.pi/5*theta_fiber\n",
        "      a_ratio_res=1+8*a_ratio\n",
        "      y0_res=-1.5+3*y0\n",
        "      print(theta_fiber_res.numpy())\n",
        "      print(a_ratio_res.numpy())\n",
        "      print(y0_res.numpy())\n",
        "      print()\n",
        "\n",
        "  return theta_fiber_res, a_ratio_res, y0_res"
      ],
      "metadata": {
        "id": "4BCP0paSvWby"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# measurement points\n",
        "ind_disp = 0\n",
        "xmeas = CP2data[ind_disp][0]\n",
        "ymeas = CP2data[ind_disp][1]\n",
        "tmeas = CP2data[ind_disp][2]\n",
        "theta_fiber, a_ratio, y0 = checkpoint2_solution(xmeas, ymeas , tmeas)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wIoU_qlaxFJ4",
        "outputId": "7e981ee0-6016-40a7-e59a-f3364fb1655f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Calling GradientTape.gradient on a persistent tape inside its context is significantly less efficient than calling it outside the context (it causes the gradient ops to be recorded on the tape, leading to increased CPU and memory usage). Only call GradientTape.gradient inside the context if you actually want to trace the gradient in order to compute higher order derivatives.\n",
            "WARNING:tensorflow:5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x790493e87910> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x790493e87910> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iter =  100\n",
            "loss = [[0.00024497835718349971]]\n",
            "loss_val_param = [[0.00014578289150643506]]\n",
            "[0.]\n",
            "[5.]\n",
            "[0.62]\n",
            "iter =  200\n",
            "loss = [[0.00015555257875025602]]\n",
            "loss_val_param = [[0.00019553463209780094]]\n",
            "[0.]\n",
            "[5.]\n",
            "[0.62]\n",
            "iter =  300\n",
            "loss = [[9.0691324912714629e-05]]\n",
            "loss_val_param = [[6.2541922818241591e-05]]\n",
            "[0.]\n",
            "[5.]\n",
            "[0.62]\n",
            "iter =  400\n",
            "loss = [[7.0769423000506312e-05]]\n",
            "loss_val_param = [[4.7235452861437888e-05]]\n",
            "[0.]\n",
            "[5.]\n",
            "[0.62]\n",
            "iter =  500\n",
            "loss = [[4.3145483246447505e-05]]\n",
            "loss_val_param = [[2.985381360488135e-05]]\n",
            "[0.]\n",
            "[5.]\n",
            "[0.62]\n",
            "iter =  600\n",
            "loss = [[3.77218365897134e-05]]\n",
            "loss_val_param = [[2.6583535955221812e-05]]\n",
            "[0.]\n",
            "[5.]\n",
            "[0.62]\n",
            "iter =  700\n",
            "loss = [[3.21651964924137e-05]]\n",
            "loss_val_param = [[2.3995765162546069e-05]]\n",
            "[0.]\n",
            "[5.]\n",
            "[0.62]\n",
            "iter =  800\n",
            "loss = [[2.9775083302401288e-05]]\n",
            "loss_val_param = [[2.0197331520256153e-05]]\n",
            "[0.]\n",
            "[5.]\n",
            "[0.62]\n",
            "iter =  100\n",
            "loss = [[2.7969771744638324e-05]]\n",
            "loss_val_param = [[2.04690834600717e-05]]\n",
            "[-0.05497025]\n",
            "[5.]\n",
            "[0.62]\n",
            "\n",
            "iter =  200\n",
            "loss = [[2.6390951244393354e-05]]\n",
            "loss_val_param = [[1.8745496713910977e-05]]\n",
            "[-0.04314041]\n",
            "[5.]\n",
            "[0.62]\n",
            "\n",
            "iter =  300\n",
            "loss = [[2.4764449733407394e-05]]\n",
            "loss_val_param = [[1.7653572835058571e-05]]\n",
            "[-0.04687879]\n",
            "[5.]\n",
            "[0.62]\n",
            "\n",
            "iter =  400\n",
            "loss = [[2.3711097057395941e-05]]\n",
            "loss_val_param = [[1.7372448149581358e-05]]\n",
            "[-0.06064306]\n",
            "[5.]\n",
            "[0.62]\n",
            "\n",
            "iter =  500\n",
            "loss = [[2.3298721095112986e-05]]\n",
            "loss_val_param = [[1.7073466122594194e-05]]\n",
            "[-0.05914471]\n",
            "[5.]\n",
            "[0.62]\n",
            "\n",
            "iter =  600\n",
            "loss = [[2.2935332810157752e-05]]\n",
            "loss_val_param = [[1.7268043655416225e-05]]\n",
            "[-0.06559783]\n",
            "[5.]\n",
            "[0.62]\n",
            "\n",
            "iter =  700\n",
            "loss = [[2.1763020320673145e-05]]\n",
            "loss_val_param = [[1.6279012137333447e-05]]\n",
            "[-0.06464133]\n",
            "[5.]\n",
            "[0.62]\n",
            "\n",
            "iter =  800\n",
            "loss = [[2.078502012732419e-05]]\n",
            "loss_val_param = [[1.53328076962933e-05]]\n",
            "[-0.06334247]\n",
            "[5.]\n",
            "[0.62]\n",
            "\n",
            "\n",
            "iter =  100\n",
            "loss = [[1.022595049304127e-05]]\n",
            "loss_val_param = [[6.8672622873374084e-06]]\n",
            "[-0.06334247]\n",
            "[8.78402347]\n",
            "[0.62]\n",
            "\n",
            "iter =  200\n",
            "loss = [[9.1360741386189758e-06]]\n",
            "loss_val_param = [[6.6951276224227907e-06]]\n",
            "[-0.06334247]\n",
            "[8.33434736]\n",
            "[0.62]\n",
            "\n",
            "iter =  300\n",
            "loss = [[8.85343720612213e-06]]\n",
            "loss_val_param = [[6.2473112878056133e-06]]\n",
            "[-0.06334247]\n",
            "[8.15404376]\n",
            "[0.62]\n",
            "\n",
            "iter =  400\n",
            "loss = [[8.4580238476105091e-06]]\n",
            "loss_val_param = [[6.9413663658115736e-06]]\n",
            "[-0.06334247]\n",
            "[8.30247817]\n",
            "[0.62]\n",
            "\n",
            "iter =  500\n",
            "loss = [[9.214216333809797e-06]]\n",
            "loss_val_param = [[6.4803428193676013e-06]]\n",
            "[-0.06334247]\n",
            "[8.58381801]\n",
            "[0.62]\n",
            "\n",
            "iter =  600\n",
            "loss = [[9.8735279580197574e-06]]\n",
            "loss_val_param = [[5.4539800579350208e-06]]\n",
            "[-0.06334247]\n",
            "[8.84311474]\n",
            "[0.62]\n",
            "\n",
            "iter =  700\n",
            "loss = [[7.8210231106751678e-06]]\n",
            "loss_val_param = [[5.84384184426129e-06]]\n",
            "[-0.06334247]\n",
            "[8.97280651]\n",
            "[0.62]\n",
            "\n",
            "iter =  800\n",
            "loss = [[6.4656002408375669e-06]]\n",
            "loss_val_param = [[4.6145011726877061e-06]]\n",
            "[-0.06334247]\n",
            "[8.93352198]\n",
            "[0.62]\n",
            "\n",
            "\n",
            "iter =  100\n",
            "loss = [[6.4160798499277733e-06]]\n",
            "loss_val_param = [[4.0829212543155983e-06]]\n",
            "[-0.06334247]\n",
            "[8.93352198]\n",
            "[0.74197374]\n",
            "\n",
            "iter =  200\n",
            "loss = [[5.6993853877338817e-06]]\n",
            "loss_val_param = [[4.7211880891785479e-06]]\n",
            "[-0.06334247]\n",
            "[8.93352198]\n",
            "[0.718674]\n",
            "\n",
            "iter =  300\n",
            "loss = [[4.8962075802813596e-06]]\n",
            "loss_val_param = [[3.617846574269465e-06]]\n",
            "[-0.06334247]\n",
            "[8.93352198]\n",
            "[0.73979903]\n",
            "\n",
            "iter =  400\n",
            "loss = [[5.5432004518683246e-06]]\n",
            "loss_val_param = [[4.7732121594261516e-06]]\n",
            "[-0.06334247]\n",
            "[8.93352198]\n",
            "[0.73328495]\n",
            "\n",
            "iter =  500\n",
            "loss = [[6.643154978334989e-06]]\n",
            "loss_val_param = [[3.9138282425200243e-06]]\n",
            "[-0.06334247]\n",
            "[8.93352198]\n",
            "[0.73301941]\n",
            "\n",
            "iter =  600\n",
            "loss = [[1.1559313159691696e-05]]\n",
            "loss_val_param = [[4.6175890332063685e-06]]\n",
            "[-0.06334247]\n",
            "[8.93352198]\n",
            "[0.74386066]\n",
            "\n",
            "iter =  700\n",
            "loss = [[9.1511382375241051e-06]]\n",
            "loss_val_param = [[8.1400680672068256e-06]]\n",
            "[-0.06334247]\n",
            "[8.93352198]\n",
            "[0.7511304]\n",
            "\n",
            "iter =  800\n",
            "loss = [[5.8146128977658871e-06]]\n",
            "loss_val_param = [[5.1293345167605877e-06]]\n",
            "[-0.06334247]\n",
            "[8.93352198]\n",
            "[0.75543666]\n",
            "\n",
            "\n",
            "iter =  100\n",
            "loss = [[3.6152716987895029e-06]]\n",
            "loss_val_param = [[3.067843387195906e-06]]\n",
            "[-0.09197953]\n",
            "[8.95487198]\n",
            "[0.75455845]\n",
            "\n",
            "iter =  200\n",
            "loss = [[2.9056842276136627e-06]]\n",
            "loss_val_param = [[2.3188638568368361e-06]]\n",
            "[-0.12495844]\n",
            "[8.9880213]\n",
            "[0.79947954]\n",
            "\n",
            "iter =  300\n",
            "loss = [[2.1063817358358938e-06]]\n",
            "loss_val_param = [[2.2496560666655344e-06]]\n",
            "[-0.1561592]\n",
            "[8.99765668]\n",
            "[0.83694434]\n",
            "\n",
            "iter =  400\n",
            "loss = [[1.7001798931846837e-06]]\n",
            "loss_val_param = [[2.1237321731738368e-06]]\n",
            "[-0.1801079]\n",
            "[8.99884864]\n",
            "[0.86827796]\n",
            "\n",
            "iter =  500\n",
            "loss = [[1.4503535084561393e-06]]\n",
            "loss_val_param = [[1.7562583213635367e-06]]\n",
            "[-0.19886116]\n",
            "[8.99615989]\n",
            "[0.89089379]\n",
            "\n",
            "iter =  600\n",
            "loss = [[1.3658058265856211e-06]]\n",
            "loss_val_param = [[1.8427950700328781e-06]]\n",
            "[-0.21573123]\n",
            "[9.00015713]\n",
            "[0.91408688]\n",
            "\n",
            "iter =  700\n",
            "loss = [[1.1620227583915939e-06]]\n",
            "loss_val_param = [[1.4363602309803749e-06]]\n",
            "[-0.22732774]\n",
            "[8.99700599]\n",
            "[0.931481]\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}